name: Per-Issue Deploy

on:
  push:
    branches:
      - 'fix/issue-*'
      - 'feat/issue-*'
      - 'feature/issue-*'
      - 'claude/issue-*'
    paths:
      - 'frontend/**'
      - 'backend/**'
      - '!**/*.md'

permissions:
  contents: read
  issues: write
  id-token: write

env:
  PROJECT_ID: duotopia-472708
  REGION: asia-east1
  REPOSITORY: duotopia-repo

jobs:
  extract:
    runs-on: ubuntu-latest
    outputs:
      issue_number: ${{ steps.extract.outputs.issue_number }}
    steps:
      - name: Extract issue number
        id: extract
        run: |
          echo "ğŸ” DEBUG: Starting extract job"
          # Extract first number after 'issue-' pattern
          ISSUE_NUM=$(echo "${{ github.ref_name }}" | grep -oP 'issue-\K\d+')
          echo "issue_number=$ISSUE_NUM" >> $GITHUB_OUTPUT
          echo "âœ… Issue number: $ISSUE_NUM"

  test-extract:
    runs-on: ubuntu-latest
    needs: extract
    steps:
      - name: Test extract output
        run: |
          echo "ğŸ” DEBUG: Testing extract output"
          echo "Issue from extract: ${{ needs.extract.outputs.issue_number }}"

  deploy-backend:
    runs-on: ubuntu-latest
    needs: extract
    outputs:
      url: ${{ steps.deploy.outputs.url }}
    steps:
      - uses: actions/checkout@v4

      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Setup Python for migrations
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run Alembic database migrations
        working-directory: ./backend
        env:
          # Use pooler URL for GitHub Actions (direct connection blocked by Supabase)
          DATABASE_URL: ${{ secrets.STAGING_DATABASE_POOLER_URL }}
          STAGING_SUPABASE_POOLER_URL: ${{ secrets.STAGING_DATABASE_POOLER_URL }}
        run: |
          echo "ğŸ” Installing dependencies for migrations..."
          pip install alembic psycopg2-binary sqlalchemy python-dotenv
          echo "ğŸ”„ Running Alembic database migrations..."
          echo "ğŸ“Š Current migration status:"
          alembic current || echo "No current revision"
          echo "ğŸ”„ Upgrading to latest migration..."
          STAMPED=false
          alembic upgrade head 2>&1 | tee /tmp/alembic_output.txt
          ALEMBIC_EXIT=$?
          if [ $ALEMBIC_EXIT -ne 0 ] || grep -q "FAILED\|Can't locate revision\|overlaps with" /tmp/alembic_output.txt; then
            if grep -q "Can't locate revision\|overlaps with\|FAILED" /tmp/alembic_output.txt; then
              echo "âš ï¸ Migration path issue detected, stamping to current head..."
              CURRENT_HEAD=$(alembic heads | head -1 | awk '{print $1}')
              echo "ğŸ“Œ Stamping to revision: $CURRENT_HEAD"
              alembic stamp "$CURRENT_HEAD"
              STAMPED=true
              echo "âœ… Database stamped successfully"
            else
              echo "âŒ Migration failed with unexpected error"
              cat /tmp/alembic_output.txt
              exit 1
            fi
          fi
          echo "âœ… Migrations complete"

      - name: Deploy backend to Cloud Run
        id: deploy
        working-directory: ./backend
        run: |
          echo "ğŸ” DEBUG: Starting real backend deployment"
          ISSUE=${{ needs.extract.outputs.issue_number }}
          SERVICE="duotopia-preview-issue-${ISSUE}-backend"
          IMAGE="${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${SERVICE}:${{ github.sha }}"

          echo "ğŸ” DEBUG: Configuring docker"
          gcloud auth configure-docker ${REGION}-docker.pkg.dev

          echo "ğŸ” DEBUG: Building image"
          docker build -t "${IMAGE}" .

          echo "ğŸ” DEBUG: Pushing image"
          docker push "${IMAGE}"

          echo "ğŸ” DEBUG: Deploying to Cloud Run"

          # ä½¿ç”¨ placeholderï¼Œæœƒåœ¨ frontend éƒ¨ç½²å¾Œæ›´æ–°ç‚ºå¯¦éš› URL
          FRONTEND_URL="https://placeholder-will-be-updated.run.app"

          # ç’°å¢ƒè®Šæ•¸è¨­å®šï¼ˆä½¿ç”¨ staging çš„é…ç½®ï¼‰
          ENV_VARS="DATABASE_URL=${{ secrets.STAGING_DATABASE_URL }}"
          ENV_VARS="$ENV_VARS,DATABASE_POOLER_URL=${{ secrets.STAGING_DATABASE_POOLER_URL }}"
          ENV_VARS="$ENV_VARS,DATABASE_TYPE=supabase"
          ENV_VARS="$ENV_VARS,PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}"
          ENV_VARS="$ENV_VARS,JWT_SECRET=${{ secrets.STAGING_JWT_SECRET }}"
          ENV_VARS="$ENV_VARS,JWT_ALGORITHM=HS256"
          ENV_VARS="$ENV_VARS,JWT_EXPIRE_MINUTES=1440"
          ENV_VARS="$ENV_VARS,ENVIRONMENT=preview"
          ENV_VARS="$ENV_VARS,SUPABASE_URL=${{ secrets.STAGING_SUPABASE_URL }}"
          ENV_VARS="$ENV_VARS,SUPABASE_KEY=${{ secrets.STAGING_SUPABASE_ANON_KEY }}"
          ENV_VARS="$ENV_VARS,FRONTEND_URL=${FRONTEND_URL}"
          ENV_VARS="$ENV_VARS,OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
          ENV_VARS="$ENV_VARS,USE_VERTEX_AI=${{ vars.USE_VERTEX_AI || 'false' }}"
          ENV_VARS="$ENV_VARS,VERTEX_AI_PROJECT_ID=${PROJECT_ID}"
          ENV_VARS="$ENV_VARS,VERTEX_AI_LOCATION=us-central1"
          ENV_VARS="$ENV_VARS,SMTP_HOST=${{ secrets.SMTP_HOST }}"
          ENV_VARS="$ENV_VARS,SMTP_PORT=${{ secrets.SMTP_PORT }}"
          ENV_VARS="$ENV_VARS,SMTP_USER=${{ secrets.SMTP_USER }}"
          ENV_VARS="$ENV_VARS,SMTP_PASSWORD=${{ secrets.SMTP_PASSWORD }}"
          ENV_VARS="$ENV_VARS,FROM_EMAIL=${{ secrets.FROM_EMAIL }}"
          ENV_VARS="$ENV_VARS,FROM_NAME=${{ secrets.FROM_NAME }}"
          ENV_VARS="$ENV_VARS,AZURE_SPEECH_KEY=${{ secrets.AZURE_SPEECH_KEY }}"
          ENV_VARS="$ENV_VARS,AZURE_SPEECH_REGION=${{ secrets.AZURE_SPEECH_REGION }}"
          ENV_VARS="$ENV_VARS,AZURE_SPEECH_ENDPOINT=${{ secrets.AZURE_SPEECH_ENDPOINT }}"
          ENV_VARS="$ENV_VARS,GCP_PROJECT_ID=${PROJECT_ID}"
          ENV_VARS="$ENV_VARS,REGION=${REGION}"
          ENV_VARS="$ENV_VARS,GCS_BUCKET_NAME=duotopia-audio"
          ENV_VARS="$ENV_VARS,USE_GCS_STORAGE=true"
          ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_ID=${{ secrets.TAPPAY_SANDBOX_APP_ID }}"
          ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_KEY=${{ secrets.TAPPAY_SANDBOX_APP_KEY }}"
          ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_PARTNER_KEY=${{ secrets.TAPPAY_SANDBOX_PARTNER_KEY }}"
          ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_MERCHANT_ID=${{ secrets.TAPPAY_SANDBOX_MERCHANT_ID }}"
          ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_ID=${{ secrets.TAPPAY_PRODUCTION_APP_ID }}"
          ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_KEY=${{ secrets.TAPPAY_PRODUCTION_APP_KEY }}"
          ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_PARTNER_KEY=${{ secrets.TAPPAY_PRODUCTION_PARTNER_KEY }}"
          ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_MERCHANT_ID=${{ secrets.TAPPAY_PRODUCTION_MERCHANT_ID }}"

          echo "ğŸ” DEBUG: Deploying to Cloud Run (without output capture)"
          gcloud run deploy "${SERVICE}" \
            --image "${IMAGE}" \
            --platform managed \
            --region ${REGION} \
            --allow-unauthenticated \
            --port 8080 \
            --memory 1Gi \
            --cpu 1 \
            --timeout 300 \
            --concurrency 10 \
            --max-instances 1 \
            --min-instances 0 \
            --set-env-vars "${ENV_VARS}" \
            --labels "environment=preview,issue=${ISSUE}"

          echo "ğŸ” DEBUG: Getting service URL from gcloud"
          URL=$(gcloud run services describe "${SERVICE}" \
            --region ${REGION} \
            --format='value(status.url)')

          # Validate URL was extracted
          if [ -z "$URL" ]; then
            echo "âŒ ERROR: Failed to extract service URL from deployment output"
            echo "ğŸ“‹ Deploy output:"
            echo "$DEPLOY_OUTPUT"
            exit 1
          fi

          # Validate URL format (Cloud Run URLs: https://service.region.run.app or https://service.run.app)
          if [[ ! "$URL" =~ ^https://[a-z0-9-]+(\.[a-z0-9-]+)?\.run\.app$ ]]; then
            echo "âŒ ERROR: Extracted URL has invalid format: $URL"
            echo "Expected format: https://service-name-hash.region.run.app or https://service-name.run.app"
            exit 1
          fi

          echo "url=${URL}" >> $GITHUB_OUTPUT
          echo "âœ… Backend deployed: ${URL}"

  seed-database:
    runs-on: ubuntu-latest
    needs: [deploy-backend]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          echo "ğŸ“¦ Installing Python dependencies..."
          pip install --upgrade pip
          pip install -r backend/requirements.txt

      - name: Seed staging database
        env:
          DATABASE_URL: ${{ secrets.STAGING_DATABASE_POOLER_URL }}
          SEED_DEFAULT_PASSWORD: ${{ secrets.SEED_DEFAULT_PASSWORD }}
        run: |
          echo "ğŸŒ± Seeding staging database..."
          cd backend

          echo "ğŸ“ Running seed_local_org.py..."
          python3 seed_local_org.py

          echo "ğŸ“ Running seed_demo_data.py..."
          python3 seed_demo_data.py

          echo "âœ… Database seeded successfully!"

  deploy-frontend:
    runs-on: ubuntu-latest
    needs: [extract, deploy-backend, seed-database]
    outputs:
      url: ${{ steps.deploy.outputs.url }}
    steps:
      - uses: actions/checkout@v4

      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Deploy frontend to Cloud Run
        id: deploy
        working-directory: ./frontend
        run: |
          echo "ğŸ” DEBUG: Starting frontend deployment"
          ISSUE=${{ needs.extract.outputs.issue_number }}
          SERVICE="duotopia-preview-issue-${ISSUE}-frontend"
          IMAGE="${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${SERVICE}:${{ github.sha }}"
          BACKEND_URL="${{ needs.deploy-backend.outputs.url }}"

          echo "ğŸ” DEBUG: Backend URL: ${BACKEND_URL}"
          echo "ğŸ” DEBUG: Configuring docker"
          gcloud auth configure-docker ${REGION}-docker.pkg.dev

          echo "ğŸ” DEBUG: Building frontend image"
          docker build \
            -f Dockerfile.staging \
            --build-arg VITE_API_URL="${BACKEND_URL}" \
            --build-arg VITE_ENVIRONMENT=preview \
            --build-arg VITE_TAPPAY_SERVER_TYPE=production \
            --build-arg VITE_TAPPAY_PRODUCTION_APP_ID="${{ secrets.TAPPAY_PRODUCTION_APP_ID }}" \
            --build-arg VITE_TAPPAY_PRODUCTION_APP_KEY="${{ secrets.TAPPAY_PRODUCTION_APP_KEY }}" \
            -t "${IMAGE}" \
            .

          echo "ğŸ” DEBUG: Pushing frontend image"
          docker push "${IMAGE}"

          echo "ğŸ” DEBUG: Deploying frontend to Cloud Run and capturing output"
          DEPLOY_OUTPUT=$(gcloud run deploy "${SERVICE}" \
            --image "${IMAGE}" \
            --platform managed \
            --region ${REGION} \
            --allow-unauthenticated \
            --port 80 \
            --memory 256Mi \
            --cpu 500m \
            --concurrency 1 \
            --max-instances 1 \
            --min-instances 0 \
            --labels "environment=preview,issue=${ISSUE}" 2>&1)

          echo "$DEPLOY_OUTPUT"

          echo "ğŸ” DEBUG: Extracting frontend URL from deploy output"
          URL=$(echo "$DEPLOY_OUTPUT" | grep -F "Service URL:" | awk '{print $NF}' | xargs)

          # Validate URL was extracted
          if [ -z "$URL" ]; then
            echo "âŒ ERROR: Failed to extract service URL from deployment output"
            echo "ğŸ“‹ Deploy output:"
            echo "$DEPLOY_OUTPUT"
            exit 1
          fi

          # Validate URL format (Cloud Run URLs: https://service.region.run.app or https://service.run.app)
          if [[ ! "$URL" =~ ^https://[a-z0-9-]+(\.[a-z0-9-]+)?\.run\.app$ ]]; then
            echo "âŒ ERROR: Extracted URL has invalid format: $URL"
            echo "Expected format: https://service-name-hash.region.run.app or https://service-name.run.app"
            exit 1
          fi

          echo "url=${URL}" >> $GITHUB_OUTPUT
          echo "âœ… Frontend deployed: ${URL}"

  update-backend-frontend-url:
    runs-on: ubuntu-latest
    needs: [extract, deploy-backend, deploy-frontend]
    if: success()
    steps:
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: Update backend FRONTEND_URL with actual frontend URL
        run: |
          echo "ğŸ”„ Updating backend FRONTEND_URL..."
          ISSUE=${{ needs.extract.outputs.issue_number }}
          SERVICE="duotopia-preview-issue-${ISSUE}-backend"
          FRONTEND_URL="${{ needs.deploy-frontend.outputs.url }}"

          echo "ğŸ“ Frontend URL: ${FRONTEND_URL}"

          # Update only the FRONTEND_URL environment variable
          gcloud run services update "${SERVICE}" \
            --platform managed \
            --region ${{ env.REGION }} \
            --update-env-vars "FRONTEND_URL=${FRONTEND_URL}"

          echo "âœ… Backend FRONTEND_URL updated to: ${FRONTEND_URL}"

  cleanup-images:
    runs-on: ubuntu-latest
    needs: [extract, deploy-backend, deploy-frontend, update-backend-frontend-url]
    if: success()
    steps:
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2

      - name: ğŸ§¹ Clean Old Images for This Issue
        run: |
          echo "ğŸ§¹ Cleaning old images for Issue #${{ needs.extract.outputs.issue_number }}..."

          KEEP_COUNT=1  # Keep only the latest version
          REGISTRY="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}"
          ISSUE="${{ needs.extract.outputs.issue_number }}"

          # Services to clean for this issue
          services=(
            "duotopia-preview-issue-${ISSUE}-backend"
            "duotopia-preview-issue-${ISSUE}-frontend"
          )

          total_deleted=0

          for service in "${services[@]}"; do
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "ğŸ“¦ Service: $service"

            FULL_PATH="${REGISTRY}/${service}"

            # Get digests sorted by CREATE_TIME (newest first)
            DIGESTS=$(gcloud artifacts docker images list "${FULL_PATH}" \
              --sort-by="~CREATE_TIME" 2>&1 | grep "sha256:" | awk '{print $2}' || true)

            if [ -z "$DIGESTS" ]; then
              echo "   â„¹ï¸  No images found"
              continue
            fi

            TOTAL=$(echo "$DIGESTS" | wc -l | tr -d ' ')
            echo "   ğŸ“Š Total images: $TOTAL"

            if [ "$TOTAL" -le "$KEEP_COUNT" ]; then
              echo "   âœ… Already optimal ($TOTAL <= $KEEP_COUNT)"
              continue
            fi

            # Keep the first KEEP_COUNT, delete the rest
            DELETE_DIGESTS=$(echo "$DIGESTS" | tail -n +"$((KEEP_COUNT + 1))")
            DELETE_COUNT=$(echo "$DELETE_DIGESTS" | wc -l | tr -d ' ')

            echo "   âœ… Keeping $KEEP_COUNT newest image(s)"
            echo "   ğŸ—‘ï¸  Deleting $DELETE_COUNT old image(s)..."

            echo "$DELETE_DIGESTS" | while read -r digest; do
              if [ -n "$digest" ]; then
                IMAGE_URI="${FULL_PATH}@${digest}"
                short_digest="${digest:7:12}"

                if gcloud artifacts docker images delete "${IMAGE_URI}" --delete-tags --quiet 2>&1; then
                  echo "      âœ… Deleted: ${short_digest}"
                  total_deleted=$((total_deleted + 1))
                else
                  echo "      âš ï¸  Failed: ${short_digest}"
                fi
              fi
            done

            echo ""
          done

          if [ $total_deleted -gt 0 ]; then
            echo "âœ… Cleaned up $total_deleted old image(s) for Issue #${ISSUE}"
          else
            echo "âœ… No cleanup needed - already optimal"
          fi

  comment:
    runs-on: ubuntu-latest
    needs: [extract, deploy-backend, deploy-frontend, update-backend-frontend-url, cleanup-images]
    if: success()
    permissions:
      issues: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - uses: actions/github-script@v7
        env:
          ISSUE: ${{ needs.extract.outputs.issue_number }}
          BACKEND: ${{ needs.deploy-backend.outputs.url }}
          FRONTEND: ${{ needs.deploy-frontend.outputs.url }}
        with:
          script: |
            const issue = process.env.ISSUE;
            const frontend = process.env.FRONTEND;
            const backend = process.env.BACKEND;
            const sha = context.sha.substring(0, 7);
            const branch = context.ref.replace('refs/heads/', '');
            const now = new Date().toLocaleString('zh-TW', { timeZone: 'Asia/Taipei' });

            // Get commit message
            const { execSync } = require('child_process');
            const commitMsg = execSync(`git log -1 --pretty=format:"%s"`, { encoding: 'utf-8' });
            const commitBody = execSync(`git log -1 --pretty=format:"%b"`, { encoding: 'utf-8' }).trim();

            // Generate smart change summary based on commit type
            let changeSummary = '';
            if (commitMsg.match(/^fix/i)) {
              changeSummary = `ğŸ”§ æœ¬æ¬¡ä¿®å¾©ï¼š${commitMsg.replace(/^fix[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^feat/i)) {
              changeSummary = `âœ¨ æ–°åŠŸèƒ½ï¼š${commitMsg.replace(/^feat[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^refactor/i)) {
              changeSummary = `â™»ï¸ é‡æ§‹ï¼š${commitMsg.replace(/^refactor[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^style/i)) {
              changeSummary = `ğŸ’„ æ¨£å¼èª¿æ•´ï¼š${commitMsg.replace(/^style[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^perf/i)) {
              changeSummary = `âš¡ æ€§èƒ½å„ªåŒ–ï¼š${commitMsg.replace(/^perf[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^test/i)) {
              changeSummary = `âœ… æ¸¬è©¦æ›´æ–°ï¼š${commitMsg.replace(/^test[:(]\s*/i, '')}`;
            } else if (commitMsg.match(/^docs/i)) {
              changeSummary = `ğŸ“ æ–‡æª”æ›´æ–°ï¼š${commitMsg.replace(/^docs[:(]\s*/i, '')}`;
            } else {
              changeSummary = `ğŸ“ ${commitMsg}`;
            }

            // Build comment body
            const bodyParts = [
              'âœ… **éƒ¨ç½²å®Œæˆï¼**',
              '',
              changeSummary
            ];

            // Add commit body if exists (detailed description)
            if (commitBody && commitBody.length > 0) {
              // Filter out common markers
              const cleanBody = commitBody
                .split('\n')
                .filter(line => !line.includes('Generated with') && !line.includes('Co-Authored-By'))
                .join('\n')
                .trim();

              if (cleanBody) {
                bodyParts.push('');
                bodyParts.push(cleanBody);
              }
            }

            bodyParts.push(
              '',
              '**æ¸¬è©¦ç’°å¢ƒå·²æ›´æ–°**ï¼š',
              `- ğŸŒ **Frontend**: ${frontend}`,
              `- âš™ï¸ **Backend**: ${backend}`,
              '',
              '@kaddy-eunice è«‹æ¸¬è©¦æœ€æ–°ç‰ˆæœ¬',
              '',
              '**éƒ¨ç½²è³‡è¨Š**:',
              `- ğŸ“ Commit: \`${sha}\``,
              `- ğŸ”§ åˆ†æ”¯: \`${branch}\``,
              `- â° éƒ¨ç½²æ™‚é–“: ${now}`,
              '',
              'ğŸ’¡ Min instances = 0 (é–’ç½®æ™‚ä¸ç”¢ç”Ÿè²»ç”¨)',
              'âœï¸ æ¸¬è©¦å®Œæˆå¾Œè«‹å›è¦†ã€Œæ¸¬è©¦é€šéã€'
            );

            const body = bodyParts.join('\n');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: parseInt(issue),
              body: body
            });
