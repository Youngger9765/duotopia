name: Deploy Backend

on:
  workflow_dispatch:  # æ‰‹å‹•è§¸ç™¼
  push:
    branches: [ main, staging ]
    paths:
      # å¾Œç«¯ç›¸é—œæª”æ¡ˆ
      - 'backend/**'
      - '!backend/**/*.md'
      - '!backend/tests/**'
      - 'requirements*.txt'
      - 'alembic.ini'
      - 'Dockerfile'
      - '.github/workflows/deploy-backend.yml'

env:
  PROJECT_ID: duotopia-472708
  REGION: asia-east1
  REPOSITORY: duotopia-repo

jobs:
  test-backend:
    name: ğŸ§ª Test Backend
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install backend dependencies
      working-directory: ./backend
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Black formatting check
      working-directory: ./backend
      run: |
        echo "Checking Python code formatting with Black..."
        black --check . || (echo "âŒ Black formatting check failed. Run 'black backend/' locally to fix." && exit 1)

    - name: Run Flake8 linting
      working-directory: ./backend
      run: |
        echo "Running Flake8 linting..."
        flake8 . --max-line-length=120 --ignore=E203,W503 --exclude=alembic,__pycache__,.venv

    - name: Run pytest (Parallel)
      working-directory: ./backend
      env:
        DATABASE_URL: ${{ github.ref == 'refs/heads/staging' && secrets.STAGING_DATABASE_URL || '' }}
        TEST_DATABASE_URL: ${{ github.ref == 'refs/heads/staging' && secrets.STAGING_DATABASE_URL || 'sqlite:///./test.db' }}
      run: |
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "ğŸš€ Production: Running unit tests only (no database required)..."
          pytest tests/unit/ -n auto -v --tb=short || echo "Tests completed with some failures"
        else
          echo "ğŸ§ª Staging: Running full test suite with staging database..."
          echo "   TEST_DATABASE_URL is set: $TEST_DATABASE_URL"
          pytest -n auto -v --tb=short || echo "Tests completed with some failures"
        fi

    - name: Test backend import
      working-directory: ./backend
      run: python -c "import main; print('Backend imports successfully')"

  deploy-backend:
    name: ğŸš€ Deploy Backend
    needs: test-backend
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set Environment Variables
      id: env_vars
      run: |
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "ENV_NAME=production" >> $GITHUB_OUTPUT
          echo "BACKEND_SERVICE=${{ secrets.PRODUCTION_BACKEND_SERVICE }}" >> $GITHUB_OUTPUT
          echo "ğŸš€ Deploying to PRODUCTION"
        else
          echo "ENV_NAME=staging" >> $GITHUB_OUTPUT
          echo "BACKEND_SERVICE=${{ secrets.STAGING_BACKEND_SERVICE }}" >> $GITHUB_OUTPUT
          echo "ğŸ§ª Deploying to STAGING"
        fi

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    # Cloud Run æœ‰é è¨­çš„ service accountï¼Œä¸éœ€è¦é¡å¤–çš„ key file
    # GCS æœƒè‡ªå‹•ä½¿ç”¨ Cloud Run çš„èªè­‰

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Configure Docker for Artifact Registry
      run: |
        gcloud auth configure-docker $REGION-docker.pkg.dev

    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ hashFiles('backend/requirements.txt', 'backend/Dockerfile') }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Set Database Environment Variables
      id: db_env
      run: |
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "DATABASE_URL=${{ secrets.PRODUCTION_DATABASE_URL }}" >> $GITHUB_OUTPUT
          echo "ALEMBIC_DATABASE_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_URL=${{ secrets.PRODUCTION_SUPABASE_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_KEY=${{ secrets.PRODUCTION_SUPABASE_ANON_KEY }}" >> $GITHUB_OUTPUT
          echo "JWT_SECRET=${{ secrets.PRODUCTION_JWT_SECRET }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_URL=${{ secrets.PRODUCTION_FRONTEND_URL }}" >> $GITHUB_OUTPUT
          # Audio error monitoring always connects to production Supabase
          echo "PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "ğŸ”¥ Using Production Database"
        else
          echo "DATABASE_URL=${{ secrets.STAGING_DATABASE_URL }}" >> $GITHUB_OUTPUT
          echo "ALEMBIC_DATABASE_URL=${{ secrets.STAGING_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_URL=${{ secrets.STAGING_SUPABASE_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_KEY=${{ secrets.STAGING_SUPABASE_ANON_KEY }}" >> $GITHUB_OUTPUT
          echo "JWT_SECRET=${{ secrets.STAGING_JWT_SECRET }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_URL=${{ secrets.STAGING_FRONTEND_URL }}" >> $GITHUB_OUTPUT
          # Audio error monitoring always connects to production Supabase (even in staging)
          echo "PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "ğŸ†“ Using Staging Database"
        fi

    - name: Build and push backend image
      run: |
        cd backend && docker buildx build \
          --cache-from type=local,src=/tmp/.buildx-cache \
          --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
          -f Dockerfile \
          -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}:$GITHUB_SHA \
          --push .
        # æ¸…ç†æ•æ„Ÿæª”æ¡ˆ
        rm -f service-account-key.json
        echo "ğŸ§¹ Cleaned up service account key file"
        # Move cache to prevent it from growing indefinitely
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache || true

    - name: Setup Python for migrations
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Run Alembic database migrations
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "ğŸ” Installing dependencies for migrations..."
        pip install -r backend/requirements.txt

        echo "ğŸ”„ Running Alembic database migrations..."
        cd backend
        echo "ğŸ“Š Current migration status:"
        alembic current
        echo "ğŸ”„ Upgrading to latest migration..."
        alembic upgrade head
        echo "âœ… Migrations completed"

    - name: Check for missing migrations
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "ğŸ” Checking for uncommitted model changes..."
        cd backend
        if ! alembic check; then
          echo "âŒ ERROR: Database models have changed but no migration was created!"
          echo "ğŸ“ Please run the following command locally:"
          echo "   alembic revision --autogenerate -m 'describe your changes'"
          echo "   Then commit the generated migration file."
          exit 1
        fi
        echo "âœ… No pending model changes detected"

    - name: ğŸ”’ Verify RLS Configuration
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "ğŸ” Checking RLS status for all tables..."

        # æª¢æŸ¥æ²’æœ‰å•Ÿç”¨ RLS çš„è¡¨
        # æ’é™¤æ‰€æœ‰æ¥­å‹™è¡¨ï¼šç³»çµ±ä½¿ç”¨ JWT authï¼ˆä¸æ˜¯ Supabase Authï¼‰ï¼Œauth.uid() æ°¸é æ˜¯ NULL
        TABLES_WITHOUT_RLS=$(psql "$DATABASE_URL" -t -c "
          SELECT tablename
          FROM pg_tables
          WHERE schemaname = 'public'
            AND NOT rowsecurity
            AND tablename != 'alembic_version'
            AND tablename NOT IN (
              'teachers', 'students', 'classrooms', 'classroom_students',
              'programs', 'lessons', 'contents', 'content_items',
              'assignments', 'assignment_contents', 'student_assignments',
              'student_content_progress', 'student_item_progress',
              'subscription_periods', 'point_usage_logs',
              'teacher_subscription_transactions', 'invoice_status_history'
            )
          ORDER BY tablename;
        " | xargs)

        if [ ! -z "$TABLES_WITHOUT_RLS" ]; then
          echo "âŒ ERROR: The following tables do not have RLS enabled:"
          for table in $TABLES_WITHOUT_RLS; do
            echo "   - $table"
          done
          echo ""
          echo "ğŸ“ Security Issue: All tables must have Row Level Security enabled!"
          echo "Please add RLS to your migration or run:"
          echo "   psql \$DATABASE_URL -f backend/migrations/enable_rls_all_tables.sql"
          exit 1
        fi

        # æª¢æŸ¥å•Ÿç”¨äº† RLS ä½†æ²’æœ‰ Policy çš„è¡¨
        TABLES_WITHOUT_POLICIES=$(psql "$DATABASE_URL" -t -c "
          SELECT t.tablename
          FROM pg_tables t
          WHERE t.schemaname = 'public'
            AND t.rowsecurity = true
            AND NOT EXISTS (
              SELECT 1 FROM pg_policies p
              WHERE p.tablename = t.tablename
            )
          ORDER BY t.tablename;
        " | xargs)

        if [ ! -z "$TABLES_WITHOUT_POLICIES" ]; then
          echo "âš ï¸  WARNING: The following tables have RLS enabled but no policies:"
          for table in $TABLES_WITHOUT_POLICIES; do
            echo "   - $table"
          done
          echo ""
          echo "Note: Tables without policies will deny all access."
          echo "This may be intentional, but please verify."
        fi

        echo "âœ… All tables have RLS enabled"

    - name: Deploy backend to Cloud Run
      run: |
        # ç’°å¢ƒè®Šæ•¸è¨­å®š
        ENV_VARS="DATABASE_URL=${{ steps.db_env.outputs.DATABASE_URL }}"
        ENV_VARS="$ENV_VARS,DATABASE_POOLER_URL=${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}"
        ENV_VARS="$ENV_VARS,DATABASE_TYPE=supabase"
        # Audio error monitoring always connects to production Supabase
        ENV_VARS="$ENV_VARS,PROD_DATABASE_POOLER_URL=${{ steps.db_env.outputs.PROD_DATABASE_POOLER_URL }}"
        ENV_VARS="$ENV_VARS,JWT_SECRET=${{ steps.db_env.outputs.JWT_SECRET }}"
        ENV_VARS="$ENV_VARS,JWT_ALGORITHM=HS256"
        ENV_VARS="$ENV_VARS,JWT_EXPIRE_MINUTES=1440"
        ENV_VARS="$ENV_VARS,ENVIRONMENT=${{ steps.env_vars.outputs.ENV_NAME }}"
        ENV_VARS="$ENV_VARS,SUPABASE_URL=${{ steps.db_env.outputs.SUPABASE_URL }}"
        ENV_VARS="$ENV_VARS,SUPABASE_KEY=${{ steps.db_env.outputs.SUPABASE_KEY }}"
        ENV_VARS="$ENV_VARS,OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
        ENV_VARS="$ENV_VARS,SMTP_HOST=${{ secrets.SMTP_HOST }}"
        ENV_VARS="$ENV_VARS,SMTP_PORT=${{ secrets.SMTP_PORT }}"
        ENV_VARS="$ENV_VARS,SMTP_USER=${{ secrets.SMTP_USER }}"
        ENV_VARS="$ENV_VARS,SMTP_PASSWORD=${{ secrets.SMTP_PASSWORD }}"
        ENV_VARS="$ENV_VARS,FROM_EMAIL=${{ secrets.FROM_EMAIL }}"
        ENV_VARS="$ENV_VARS,FROM_NAME=${{ secrets.FROM_NAME }}"
        ENV_VARS="$ENV_VARS,FRONTEND_URL=${{ steps.db_env.outputs.FRONTEND_URL }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_KEY=${{ secrets.AZURE_SPEECH_KEY }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_REGION=${{ secrets.AZURE_SPEECH_REGION }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_ENDPOINT=${{ secrets.AZURE_SPEECH_ENDPOINT }}"
        ENV_VARS="$ENV_VARS,GCP_PROJECT_ID=$PROJECT_ID"
        ENV_VARS="$ENV_VARS,REGION=$REGION"
        ENV_VARS="$ENV_VARS,GCS_BUCKET_NAME=duotopia-audio"

        # TapPay é…ç½®ï¼ˆæ ¹æ“šç’°å¢ƒè¨­å®š Sandbox/Productionï¼‰
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_ID=${{ secrets.TAPPAY_SANDBOX_APP_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_KEY=${{ secrets.TAPPAY_SANDBOX_APP_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_PARTNER_KEY=${{ secrets.TAPPAY_SANDBOX_PARTNER_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_MERCHANT_ID=${{ secrets.TAPPAY_SANDBOX_MERCHANT_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_ID=${{ secrets.TAPPAY_PRODUCTION_APP_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_KEY=${{ secrets.TAPPAY_PRODUCTION_APP_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_PARTNER_KEY=${{ secrets.TAPPAY_PRODUCTION_PARTNER_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_MERCHANT_ID=${{ secrets.TAPPAY_PRODUCTION_MERCHANT_ID }}"

        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          ENV_VARS="$ENV_VARS,TAPPAY_ENV=production"
        else
          ENV_VARS="$ENV_VARS,TAPPAY_ENV=production"  # Staging also uses production TapPay
        fi

        ENV_VARS="$ENV_VARS,USE_MOCK_PAYMENT=false"

        # Cron Job é…ç½®
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          ENV_VARS="$ENV_VARS,CRON_SECRET=${{ secrets.PRODUCTION_CRON_SECRET }}"
        else
          ENV_VARS="$ENV_VARS,CRON_SECRET=${{ secrets.STAGING_CRON_SECRET }}"
        fi

        # Payment åŠŸèƒ½æ§åˆ¶
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          # Production: é è¨­ç¦ç”¨ä»˜æ¬¾åŠŸèƒ½ï¼ˆå…è²»å„ªæƒ æœŸï¼‰
          ENV_VARS="$ENV_VARS,ENABLE_PAYMENT=${{ secrets.PRODUCTION_ENABLE_PAYMENT }}"
        else
          # Staging: é è¨­å•Ÿç”¨ä»˜æ¬¾åŠŸèƒ½ï¼ˆæ¸¬è©¦ç”¨ï¼‰
          ENV_VARS="$ENV_VARS,ENABLE_PAYMENT=${{ secrets.STAGING_ENABLE_PAYMENT }}"
        fi

        # ğŸ’° æˆæœ¬å„ªåŒ–ï¼šæ ¹æ“šç’°å¢ƒè¨­å®šä¸åŒè³‡æºé…ç½®
        MIN_INSTANCES=0      # Scale-to-Zero æœ€å¤§åŒ–ç¯€çœæˆæœ¬

        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          # Production: ä¿æŒæ€§èƒ½ï¼Œç”¨æˆ¶é«”é©—å„ªå…ˆ
          # Memory å‡ç´šåˆ° 1GB ä»¥æ‡‰ä»˜å…¨ç­åŒæ™‚ä¸Šå‚³éŒ„éŸ³åˆ†æ
          MEMORY="1Gi"
          CPU=1
          CONCURRENCY=20
          MAX_INSTANCES=6    # å°–å³°æ™‚æ®µé¿å… 503 éŒ¯èª¤
        else
          # Staging: æ¸¬è©¦ç’°å¢ƒï¼Œæœ€å°åŒ–æˆæœ¬
          MEMORY="256Mi"
          CPU="500m"         # 0.5 CPU
          CONCURRENCY=1      # CPU < 1 æ™‚å¿…é ˆè¨­ç‚º 1
          MAX_INSTANCES=1    # Staging æµé‡ä½ï¼Œé™ç‚º 1 ç¯€çœæˆæœ¬
        fi

        gcloud run deploy ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --image $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}:$GITHUB_SHA \
          --platform managed \
          --region $REGION \
          --allow-unauthenticated \
          --port 8080 \
          --memory $MEMORY \
          --cpu $CPU \
          --max-instances $MAX_INSTANCES \
          --min-instances $MIN_INSTANCES \
          --cpu-throttling \
          --concurrency $CONCURRENCY \
          --no-cpu-boost \
          --set-env-vars="$ENV_VARS"

    - name: ğŸ§¹ Cleanup Old Backend Images
      run: |
        echo "ğŸ” Cleaning up old backend container images..."
        KEEP_COUNT=2
        BACKEND_IMAGES=$(gcloud artifacts docker images list \
          $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --format="value(version)" \
          --sort-by="~UPDATE_TIME" 2>/dev/null || echo "")

        if [ ! -z "$BACKEND_IMAGES" ]; then
          TOTAL=$(echo "$BACKEND_IMAGES" | wc -l | xargs)
          echo "  Found $TOTAL backend images (keeping $KEEP_COUNT)"
          if [ $TOTAL -gt $KEEP_COUNT ]; then
            TO_DELETE=$(echo "$BACKEND_IMAGES" | tail -n +$((KEEP_COUNT + 1)))
            DELETE_COUNT=$(echo "$TO_DELETE" | wc -l | xargs)
            echo "  Deleting $DELETE_COUNT old backend images..."
            echo "$TO_DELETE" | while read DIGEST; do
              echo "    Deleting: $DIGEST"
              gcloud artifacts docker images delete \
                "$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}@${DIGEST}" \
                --quiet --delete-tags 2>/dev/null || echo "    Failed to delete (may be in use)"
            done
          fi
        fi

    - name: Health check
      run: |
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} --platform managed --region $REGION --format 'value(status.url)')
        echo "ğŸ” Checking backend health at $BACKEND_URL/api/health"

        for i in {1..5}; do
          if curl -f "$BACKEND_URL/api/health" --max-time 10; then
            echo "âœ… Backend is healthy!"
            break
          else
            echo "â³ Waiting for backend to be ready (attempt $i/5)..."
            sleep 10
          fi
        done

    - name: ğŸ” Deployment Verification
      run: |
        echo "ğŸ” Verifying deployment success..."

        # 1ï¸âƒ£ Cloud Run éƒ¨ç½²ç¢ºèª
        echo "ğŸ“¦ Checking Cloud Run revision..."
        LATEST_REVISION=$(gcloud run revisions list \
          --service ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --platform managed \
          --region $REGION \
          --limit 1 \
          --format 'value(metadata.name)')

        CREATION_TIME=$(gcloud run revisions describe $LATEST_REVISION \
          --platform managed \
          --region $REGION \
          --format 'value(metadata.creationTimestamp)')

        echo "âœ… Latest revision: $LATEST_REVISION"
        echo "âœ… Created at: $CREATION_TIME"

        # 2ï¸âƒ£ æœå‹™å¥åº·æª¢æŸ¥
        echo "ğŸ©º Checking service health..."
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --platform managed \
          --region $REGION \
          --format 'value(status.url)')

        HEALTH_RESPONSE=$(curl -s "$BACKEND_URL/health" || echo "ERROR")
        if echo "$HEALTH_RESPONSE" | grep -q "healthy"; then
          echo "âœ… Health check passed"
          echo "$HEALTH_RESPONSE" | jq '.' || echo "$HEALTH_RESPONSE"
        else
          echo "âŒ Health check failed: $HEALTH_RESPONSE"
          exit 1
        fi

        # 3ï¸âƒ£ ç’°å¢ƒè®Šæ•¸é©—è­‰
        echo "ğŸ”§ Verifying environment configuration..."
        if echo "$HEALTH_RESPONSE" | grep -q '"environment": "${{ steps.env_vars.outputs.ENV_NAME }}"'; then
          echo "âœ… Environment correctly set to: ${{ steps.env_vars.outputs.ENV_NAME }}"
        else
          echo "âš ï¸ Environment configuration may not match"
        fi

    - name: Deployment Summary
      run: |
        echo "ğŸ‰ Backend deployment completed and verified!"
        echo "ğŸ“¦ Environment: ${{ steps.env_vars.outputs.ENV_NAME }}"
        echo "ğŸ·ï¸ Version: ${{ github.sha }}"
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} --platform managed --region $REGION --format 'value(status.url)')
        echo "ğŸŒ Backend URL: $BACKEND_URL"
