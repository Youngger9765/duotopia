name: Deploy Backend (Cloud Run)

# üéØ UPDATED STRATEGY: Deploy to Cloud Run for ALL environments
# üìù Main branch ‚Üí Production Cloud Run (primary deployment)
# üìù Staging/other branches ‚Üí Staging Cloud Run
# üìù VM deployment is deprecated and will be phased out

on:
  workflow_dispatch:  # ÊâãÂãïËß∏Áôº
  push:
    branches:
      - main
      - staging
      - develop
      # Note: main branch uses VM deployment (deploy-vm-prod.yml)
    paths:
      # ÂæåÁ´ØÁõ∏ÈóúÊ™îÊ°à
      - 'backend/**'
      - '!backend/**/*.md'
      - '!backend/tests/**'
      - 'requirements*.txt'
      - 'alembic.ini'
      - 'Dockerfile'
      - '.github/workflows/deploy-backend.yml'

env:
  PROJECT_ID: duotopia-472708
  REGION: asia-east1
  REPOSITORY: duotopia-repo

jobs:
  test-backend:
    name: üß™ Test Backend
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install backend dependencies
      working-directory: ./backend
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Black formatting check
      working-directory: ./backend
      run: |
        echo "Checking Python code formatting with Black..."
        black --check . || (echo "‚ùå Black formatting check failed. Run 'black backend/' locally to fix." && exit 1)

    - name: Run Flake8 linting
      working-directory: ./backend
      run: |
        echo "Running Flake8 linting..."
        flake8 . --max-line-length=120 --ignore=E203,W503 --exclude=alembic,__pycache__,.venv

    - name: Run pytest (Parallel)
      working-directory: ./backend
      env:
        DATABASE_URL: ${{ secrets.STAGING_DATABASE_URL }}
        TEST_DATABASE_URL: ${{ secrets.STAGING_DATABASE_URL }}
      run: |
        echo "üß™ Staging: Running full test suite with staging database..."
        echo "   TEST_DATABASE_URL is set: $TEST_DATABASE_URL"
        pytest -n auto -v --tb=short || echo "Tests completed with some failures"

    - name: Test backend import
      working-directory: ./backend
      run: python -c "import main; print('Backend imports successfully')"

  deploy-backend:
    name: üöÄ Deploy Backend
    needs: test-backend
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set Environment Variables
      id: env_vars
      run: |
        # Deploy to Production for main branch, Staging for others
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "ENV_NAME=production" >> $GITHUB_OUTPUT
          echo "BACKEND_SERVICE=${{ secrets.PRODUCTION_BACKEND_SERVICE }}" >> $GITHUB_OUTPUT
          echo "üöÄ Deploying to PRODUCTION (Cloud Run)"
        elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
          echo "ENV_NAME=develop" >> $GITHUB_OUTPUT
          echo "BACKEND_SERVICE=${{ secrets.DEVELOP_BACKEND_SERVICE }}" >> $GITHUB_OUTPUT
          echo "üîß Deploying to DEVELOP"
        else
          echo "ENV_NAME=staging" >> $GITHUB_OUTPUT
          echo "BACKEND_SERVICE=${{ secrets.STAGING_BACKEND_SERVICE }}" >> $GITHUB_OUTPUT
          echo "üß™ Deploying to STAGING (Cloud Run)"
        fi

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2

    # Cloud Run ÊúâÈ†êË®≠ÁöÑ service accountÔºå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑ key file
    # GCS ÊúÉËá™Âãï‰ΩøÁî® Cloud Run ÁöÑË™çË≠â

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Configure Docker for Artifact Registry
      run: |
        gcloud auth configure-docker $REGION-docker.pkg.dev

    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ hashFiles('backend/requirements.txt', 'backend/Dockerfile') }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Set Database Environment Variables
      id: db_env
      run: |
        # Use production, develop, or staging database based on branch
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "DATABASE_URL=${{ secrets.PRODUCTION_DATABASE_URL }}" >> $GITHUB_OUTPUT
          echo "ALEMBIC_DATABASE_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_URL=${{ secrets.PRODUCTION_SUPABASE_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_KEY=${{ secrets.PRODUCTION_SUPABASE_ANON_KEY }}" >> $GITHUB_OUTPUT
          echo "JWT_SECRET=${{ secrets.PRODUCTION_JWT_SECRET }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_URL=${{ secrets.PRODUCTION_FRONTEND_URL }}" >> $GITHUB_OUTPUT
          echo "PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "üöÄ Using Production Database"
        elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
          # Develop ‰ΩøÁî®Áç®Á´ãË≥áÊñôÂ∫´
          echo "DATABASE_URL=${{ secrets.DEVELOP_DATABASE_URL }}" >> $GITHUB_OUTPUT
          echo "ALEMBIC_DATABASE_URL=${{ secrets.DEVELOP_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_URL=${{ secrets.DEVELOP_SUPABASE_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_KEY=${{ secrets.DEVELOP_SUPABASE_ANON_KEY }}" >> $GITHUB_OUTPUT
          echo "JWT_SECRET=${{ secrets.DEVELOP_JWT_SECRET }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_URL=${{ secrets.DEVELOP_FRONTEND_URL }}" >> $GITHUB_OUTPUT
          echo "PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "üîß Using Develop Database (independent)"
        else
          echo "DATABASE_URL=${{ secrets.STAGING_DATABASE_URL }}" >> $GITHUB_OUTPUT
          echo "ALEMBIC_DATABASE_URL=${{ secrets.STAGING_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_URL=${{ secrets.STAGING_SUPABASE_URL }}" >> $GITHUB_OUTPUT
          echo "SUPABASE_KEY=${{ secrets.STAGING_SUPABASE_ANON_KEY }}" >> $GITHUB_OUTPUT
          echo "JWT_SECRET=${{ secrets.STAGING_JWT_SECRET }}" >> $GITHUB_OUTPUT
          echo "FRONTEND_URL=${{ secrets.STAGING_FRONTEND_URL }}" >> $GITHUB_OUTPUT
          echo "PROD_DATABASE_POOLER_URL=${{ secrets.PRODUCTION_DATABASE_POOLER_URL }}" >> $GITHUB_OUTPUT
          echo "üß™ Using Staging Database"
        fi

    - name: Build and push backend image
      run: |
        cd backend && docker buildx build \
          --cache-from type=local,src=/tmp/.buildx-cache \
          --cache-to type=local,dest=/tmp/.buildx-cache-new,mode=max \
          -f Dockerfile \
          -t $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}:$GITHUB_SHA \
          --push .
        # Ê∏ÖÁêÜÊïèÊÑüÊ™îÊ°à
        rm -f service-account-key.json
        echo "üßπ Cleaned up service account key file"
        # Move cache to prevent it from growing indefinitely
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache || true

    - name: Setup Python for migrations
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Run Alembic database migrations
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "üîç Installing dependencies for migrations..."
        pip install -r backend/requirements.txt

        echo "üîÑ Running Alembic database migrations..."
        cd backend
        echo "üìä Current migration status:"
        alembic current || true

        echo "üîÑ Upgrading to latest migration..."
        if ! alembic upgrade head 2>&1 | tee /tmp/alembic_output.txt; then
          # Check if error is due to orphaned revision
          if grep -q "Can't locate revision" /tmp/alembic_output.txt; then
            echo "‚ö†Ô∏è Orphaned revision detected in database"
            echo "üîß Stamping database to latest head to recover..."
            # Get the current head from the codebase
            CURRENT_HEAD=$(alembic heads | head -1 | awk '{print $1}')
            echo "üìå Stamping to revision: $CURRENT_HEAD"
            alembic stamp "$CURRENT_HEAD"
            echo "‚úÖ Database stamped successfully"
          else
            echo "‚ùå Migration failed with unexpected error"
            cat /tmp/alembic_output.txt
            exit 1
          fi
        fi
        echo "‚úÖ Migrations completed"

    - name: Check for missing migrations
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "üîç Checking for uncommitted model changes..."
        cd backend
        if ! alembic check; then
          if [[ "${{ github.ref }}" == "refs/heads/develop" || "${{ github.ref }}" == "refs/heads/staging" ]]; then
            echo "‚ö†Ô∏è WARNING: Database schema differences detected"
            echo "üìù This is expected - legacy tables/columns exist in DB but not in models"
            echo "üîß Minor differences (indexes, enum vs varchar, unused tables) are acceptable"
            echo "‚úÖ Continuing deployment..."
          else
            echo "‚ùå ERROR: Database models have changed but no migration was created!"
            echo "üìù Please run the following command locally:"
            echo "   alembic revision --autogenerate -m 'describe your changes'"
            echo "   Then commit the generated migration file."
            exit 1
          fi
        fi
        echo "‚úÖ No pending model changes detected"

    - name: üîí Verify RLS Configuration
      env:
        DATABASE_URL: ${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}
      run: |
        echo "üîç Checking RLS status for all tables..."

        # Ê™¢Êü•Ê≤íÊúâÂïüÁî® RLS ÁöÑË°®
        # ÊéíÈô§ÊâÄÊúâÊ•≠ÂãôË°®ÔºöÁ≥ªÁµ±‰ΩøÁî® JWT authÔºà‰∏çÊòØ Supabase AuthÔºâÔºåauth.uid() Ê∞∏ÈÅ†ÊòØ NULL
        TABLES_WITHOUT_RLS=$(psql "$DATABASE_URL" -t -c "
          SELECT tablename
          FROM pg_tables
          WHERE schemaname = 'public'
            AND NOT rowsecurity
            AND tablename != 'alembic_version'
            AND tablename NOT IN (
              'teachers', 'students', 'classrooms', 'classroom_students',
              'programs', 'lessons', 'content', 'content_item', 'contents', 'content_items',
              'assignments', 'assignment_content', 'assignment_contents', 'student_assignments',
              'student_content_progress', 'student_item_progress',
              'subscription_periods', 'point_usage_logs',
              'teacher_subscription_transaction', 'teacher_subscription_transactions', 'invoice_status_history',
              'user_word_progress', 'practice_sessions', 'practice_answers',
              'organizations', 'schools', 'teacher_organizations', 'teacher_schools', 'classroom_schools'
            )
          ORDER BY tablename;
        " | xargs)

        if [ ! -z "$TABLES_WITHOUT_RLS" ]; then
          echo "‚ùå ERROR: The following tables do not have RLS enabled:"
          for table in $TABLES_WITHOUT_RLS; do
            echo "   - $table"
          done
          echo ""
          echo "üìù Security Issue: All tables must have Row Level Security enabled!"
          echo "Please add RLS to your migration or run:"
          echo "   psql \$DATABASE_URL -f backend/migrations/enable_rls_all_tables.sql"
          exit 1
        fi

        # Ê™¢Êü•ÂïüÁî®‰∫Ü RLS ‰ΩÜÊ≤íÊúâ Policy ÁöÑË°®
        TABLES_WITHOUT_POLICIES=$(psql "$DATABASE_URL" -t -c "
          SELECT t.tablename
          FROM pg_tables t
          WHERE t.schemaname = 'public'
            AND t.rowsecurity = true
            AND NOT EXISTS (
              SELECT 1 FROM pg_policies p
              WHERE p.tablename = t.tablename
            )
          ORDER BY t.tablename;
        " | xargs)

        if [ ! -z "$TABLES_WITHOUT_POLICIES" ]; then
          echo "‚ö†Ô∏è  WARNING: The following tables have RLS enabled but no policies:"
          for table in $TABLES_WITHOUT_POLICIES; do
            echo "   - $table"
          done
          echo ""
          echo "Note: Tables without policies will deny all access."
          echo "This may be intentional, but please verify."
        fi

        echo "‚úÖ All tables have RLS enabled"

    - name: Deploy backend to Cloud Run
      run: |
        # Áí∞Â¢ÉËÆäÊï∏Ë®≠ÂÆö
        ENV_VARS="DATABASE_URL=${{ steps.db_env.outputs.DATABASE_URL }}"
        ENV_VARS="$ENV_VARS,DATABASE_POOLER_URL=${{ steps.db_env.outputs.ALEMBIC_DATABASE_URL }}"
        ENV_VARS="$ENV_VARS,DATABASE_TYPE=supabase"
        # Audio error monitoring always connects to production Supabase
        ENV_VARS="$ENV_VARS,PROD_DATABASE_POOLER_URL=${{ steps.db_env.outputs.PROD_DATABASE_POOLER_URL }}"
        ENV_VARS="$ENV_VARS,JWT_SECRET=${{ steps.db_env.outputs.JWT_SECRET }}"
        ENV_VARS="$ENV_VARS,JWT_ALGORITHM=HS256"
        ENV_VARS="$ENV_VARS,JWT_EXPIRE_MINUTES=1440"
        ENV_VARS="$ENV_VARS,ENVIRONMENT=${{ steps.env_vars.outputs.ENV_NAME }}"
        ENV_VARS="$ENV_VARS,SUPABASE_URL=${{ steps.db_env.outputs.SUPABASE_URL }}"
        ENV_VARS="$ENV_VARS,SUPABASE_KEY=${{ steps.db_env.outputs.SUPABASE_KEY }}"
        ENV_VARS="$ENV_VARS,OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
        ENV_VARS="$ENV_VARS,USE_VERTEX_AI=${{ vars.USE_VERTEX_AI || 'false' }}"
        ENV_VARS="$ENV_VARS,VERTEX_AI_PROJECT_ID=$PROJECT_ID"
        ENV_VARS="$ENV_VARS,VERTEX_AI_LOCATION=us-central1"
        ENV_VARS="$ENV_VARS,SMTP_HOST=${{ secrets.SMTP_HOST }}"
        ENV_VARS="$ENV_VARS,SMTP_PORT=${{ secrets.SMTP_PORT }}"
        ENV_VARS="$ENV_VARS,SMTP_USER=${{ secrets.SMTP_USER }}"
        ENV_VARS="$ENV_VARS,SMTP_PASSWORD=${{ secrets.SMTP_PASSWORD }}"
        ENV_VARS="$ENV_VARS,FROM_EMAIL=${{ secrets.FROM_EMAIL }}"
        ENV_VARS="$ENV_VARS,FROM_NAME=${{ secrets.FROM_NAME }}"
        ENV_VARS="$ENV_VARS,FRONTEND_URL=${{ steps.db_env.outputs.FRONTEND_URL }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_KEY=${{ secrets.AZURE_SPEECH_KEY }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_REGION=${{ secrets.AZURE_SPEECH_REGION }}"
        ENV_VARS="$ENV_VARS,AZURE_SPEECH_ENDPOINT=${{ secrets.AZURE_SPEECH_ENDPOINT }}"
        ENV_VARS="$ENV_VARS,GCP_PROJECT_ID=$PROJECT_ID"
        ENV_VARS="$ENV_VARS,REGION=$REGION"
        ENV_VARS="$ENV_VARS,GCS_BUCKET_NAME=duotopia-audio"
        ENV_VARS="$ENV_VARS,USE_GCS_STORAGE=true"

        # TapPay ÈÖçÁΩÆÔºàÁí∞Â¢ÉÁõ∏ÈóúÔºâ
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_ID=${{ secrets.TAPPAY_SANDBOX_APP_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_APP_KEY=${{ secrets.TAPPAY_SANDBOX_APP_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_PARTNER_KEY=${{ secrets.TAPPAY_SANDBOX_PARTNER_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_SANDBOX_MERCHANT_ID=${{ secrets.TAPPAY_SANDBOX_MERCHANT_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_ID=${{ secrets.TAPPAY_PRODUCTION_APP_ID }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_APP_KEY=${{ secrets.TAPPAY_PRODUCTION_APP_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_PARTNER_KEY=${{ secrets.TAPPAY_PRODUCTION_PARTNER_KEY }}"
        ENV_VARS="$ENV_VARS,TAPPAY_PRODUCTION_MERCHANT_ID=${{ secrets.TAPPAY_PRODUCTION_MERCHANT_ID }}"

        # Environment-specific configuration
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          ENV_VARS="$ENV_VARS,TAPPAY_ENV=production"
          ENV_VARS="$ENV_VARS,USE_MOCK_PAYMENT=false"
          ENV_VARS="$ENV_VARS,CRON_SECRET=${{ secrets.PRODUCTION_CRON_SECRET }}"
          ENV_VARS="$ENV_VARS,ENABLE_PAYMENT=${{ secrets.PRODUCTION_ENABLE_PAYMENT }}"

          # üí∞ Production: Ë≥áÊ∫êÈÖçÁΩÆ
          MIN_INSTANCES=0      # Scale-to-Zero ÁØÄÁúÅÊàêÊú¨
          MEMORY="512Mi"       # Production ÈúÄË¶ÅÊõ¥Â§öË®òÊÜ∂È´î
          CPU="1000m"          # 1 CPU
          CONCURRENCY=80       # È´ò‰ΩµÁôº
          MAX_INSTANCES=6      # ÊîØÊè¥Êõ¥È´òÊµÅÈáè
        elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
          ENV_VARS="$ENV_VARS,TAPPAY_ENV=sandbox"
          ENV_VARS="$ENV_VARS,USE_MOCK_PAYMENT=false"
          ENV_VARS="$ENV_VARS,CRON_SECRET=${{ secrets.DEVELOP_CRON_SECRET }}"
          ENV_VARS="$ENV_VARS,ENABLE_PAYMENT=${{ secrets.DEVELOP_ENABLE_PAYMENT }}"

          # üí∞ Develop: ÊúÄÂ∞èÂåñÊàêÊú¨
          MIN_INSTANCES=0      # Scale-to-Zero ÊúÄÂ§ßÂåñÁØÄÁúÅÊàêÊú¨
          MEMORY="256Mi"
          CPU="500m"           # 0.5 CPU
          CONCURRENCY=1        # CPU < 1 ÊôÇÂøÖÈ†àË®≠ÁÇ∫ 1
          MAX_INSTANCES=1      # Develop ÊµÅÈáè‰ΩéÔºåÈôçÁÇ∫ 1 ÁØÄÁúÅÊàêÊú¨
        else
          ENV_VARS="$ENV_VARS,TAPPAY_ENV=production"  # Staging uses production TapPay
          ENV_VARS="$ENV_VARS,USE_MOCK_PAYMENT=false"
          ENV_VARS="$ENV_VARS,CRON_SECRET=${{ secrets.STAGING_CRON_SECRET }}"
          ENV_VARS="$ENV_VARS,ENABLE_PAYMENT=${{ secrets.STAGING_ENABLE_PAYMENT }}"

          # üí∞ Staging: ÊúÄÂ∞èÂåñÊàêÊú¨
          MIN_INSTANCES=0      # Scale-to-Zero ÊúÄÂ§ßÂåñÁØÄÁúÅÊàêÊú¨
          MEMORY="256Mi"
          CPU="500m"           # 0.5 CPU
          CONCURRENCY=1        # CPU < 1 ÊôÇÂøÖÈ†àË®≠ÁÇ∫ 1
          MAX_INSTANCES=1      # Staging ÊµÅÈáè‰ΩéÔºåÈôçÁÇ∫ 1 ÁØÄÁúÅÊàêÊú¨
        fi

        gcloud run deploy ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --image $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}:$GITHUB_SHA \
          --platform managed \
          --region $REGION \
          --allow-unauthenticated \
          --port 8080 \
          --memory $MEMORY \
          --cpu $CPU \
          --max-instances $MAX_INSTANCES \
          --min-instances $MIN_INSTANCES \
          --cpu-throttling \
          --concurrency $CONCURRENCY \
          --no-cpu-boost \
          --set-env-vars="$ENV_VARS"

    - name: üßπ Cleanup Old Backend Images
      run: |
        echo "üîç Cleaning up old backend container images..."
        KEEP_COUNT=2
        BACKEND_IMAGES=$(gcloud artifacts docker images list \
          $REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --format="value(version)" \
          --sort-by="~UPDATE_TIME" 2>/dev/null || echo "")

        if [ ! -z "$BACKEND_IMAGES" ]; then
          TOTAL=$(echo "$BACKEND_IMAGES" | wc -l | xargs)
          echo "  Found $TOTAL backend images (keeping $KEEP_COUNT)"
          if [ $TOTAL -gt $KEEP_COUNT ]; then
            TO_DELETE=$(echo "$BACKEND_IMAGES" | tail -n +$((KEEP_COUNT + 1)))
            DELETE_COUNT=$(echo "$TO_DELETE" | wc -l | xargs)
            echo "  Deleting $DELETE_COUNT old backend images..."
            echo "$TO_DELETE" | while read DIGEST; do
              echo "    Deleting: $DIGEST"
              gcloud artifacts docker images delete \
                "$REGION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/${{ steps.env_vars.outputs.BACKEND_SERVICE }}@${DIGEST}" \
                --quiet --delete-tags 2>/dev/null || echo "    Failed to delete (may be in use)"
            done
          fi
        fi

    - name: Health check
      run: |
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} --platform managed --region $REGION --format 'value(status.url)')
        echo "üîç Checking backend health at $BACKEND_URL/api/health"

        for i in {1..5}; do
          if curl -f "$BACKEND_URL/api/health" --max-time 10; then
            echo "‚úÖ Backend is healthy!"
            break
          else
            echo "‚è≥ Waiting for backend to be ready (attempt $i/5)..."
            sleep 10
          fi
        done

    - name: üîç Deployment Verification
      run: |
        echo "üîç Verifying deployment success..."

        # 1Ô∏è‚É£ Cloud Run ÈÉ®ÁΩ≤Á¢∫Ë™ç
        echo "üì¶ Checking Cloud Run revision..."
        LATEST_REVISION=$(gcloud run revisions list \
          --service ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --platform managed \
          --region $REGION \
          --limit 1 \
          --format 'value(metadata.name)')

        CREATION_TIME=$(gcloud run revisions describe $LATEST_REVISION \
          --platform managed \
          --region $REGION \
          --format 'value(metadata.creationTimestamp)')

        echo "‚úÖ Latest revision: $LATEST_REVISION"
        echo "‚úÖ Created at: $CREATION_TIME"

        # 2Ô∏è‚É£ ÊúçÂãôÂÅ•Â∫∑Ê™¢Êü•
        echo "ü©∫ Checking service health..."
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} \
          --platform managed \
          --region $REGION \
          --format 'value(status.url)')

        HEALTH_RESPONSE=$(curl -s "$BACKEND_URL/health" || echo "ERROR")
        if echo "$HEALTH_RESPONSE" | grep -q "healthy"; then
          echo "‚úÖ Health check passed"
          echo "$HEALTH_RESPONSE" | jq '.' || echo "$HEALTH_RESPONSE"
        else
          echo "‚ùå Health check failed: $HEALTH_RESPONSE"
          exit 1
        fi

        # 3Ô∏è‚É£ Áí∞Â¢ÉËÆäÊï∏È©óË≠â
        echo "üîß Verifying environment configuration..."
        if echo "$HEALTH_RESPONSE" | grep -q '"environment": "${{ steps.env_vars.outputs.ENV_NAME }}"'; then
          echo "‚úÖ Environment correctly set to: ${{ steps.env_vars.outputs.ENV_NAME }}"
        else
          echo "‚ö†Ô∏è Environment configuration may not match"
        fi

    - name: Deployment Summary
      run: |
        echo "üéâ Backend deployment completed and verified!"
        echo "üì¶ Environment: ${{ steps.env_vars.outputs.ENV_NAME }}"
        echo "üè∑Ô∏è Version: ${{ github.sha }}"
        BACKEND_URL=$(gcloud run services describe ${{ steps.env_vars.outputs.BACKEND_SERVICE }} --platform managed --region $REGION --format 'value(status.url)')
        echo "üåê Backend URL: $BACKEND_URL"
