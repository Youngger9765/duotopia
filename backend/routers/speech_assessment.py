"""
Azure Speech Assessment Router
è™•ç†å¾®è»Ÿç™¼éŸ³è©•ä¼° API çš„è«‹æ±‚
"""

import os
import logging
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
from io import BytesIO
import tempfile
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from sqlalchemy.orm import Session
from pydantic import BaseModel
from pydub import AudioSegment

from database import get_db
from auth import get_current_user
from performance_monitoring import trace_function, start_span, PerformanceSnapshot
from core.thread_pool import get_speech_thread_pool, get_audio_thread_pool
from models import (
    Student,
    StudentContentProgress,
    StudentAssignment,
    StudentItemProgress,
    ContentItem,
    Assignment,
)
from services.quota_service import QuotaService
from services.bigquery_logger import get_bigquery_logger
from sqlalchemy.orm import joinedload

# è¨­å®š logger
logger = logging.getLogger(__name__)

# ğŸ• Azure Speech API Timeout è¨­å®šï¼ˆç§’ï¼‰
AZURE_SPEECH_TIMEOUT = 20  # Azure Speech API timeout in seconds

router = APIRouter(
    prefix="/api/speech",
    tags=["speech_assessment"],
    responses={404: {"description": "Not found"}},
)

# è¨­å®šé™åˆ¶
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
ALLOWED_AUDIO_FORMATS = [
    "audio/wav",
    "audio/webm",
    "audio/webm;codecs=opus",
    "audio/mp3",
    "audio/mpeg",
    "audio/mp4",  # macOS Safari ä½¿ç”¨ MP4 æ ¼å¼
    "video/mp4",  # æŸäº›ç€è¦½å™¨å¯èƒ½ç”¨ video/mp4
    "application/octet-stream",  # ç€è¦½å™¨ä¸Šå‚³æ™‚çš„é€šç”¨é¡å‹
]


async def get_current_student(
    db: Session = Depends(get_db), current_user: dict = Depends(get_current_user)
) -> Student:
    """ç²å–ç•¶å‰èªè­‰çš„å­¸ç”Ÿ"""
    student_id = int(current_user.get("sub"))
    student = db.query(Student).filter(Student.id == student_id).first()

    if not student:
        raise HTTPException(status_code=404, detail="Student not found")

    return student


class AssessmentResponse(BaseModel):
    """ç™¼éŸ³è©•ä¼°å›æ‡‰ schema"""

    id: Optional[int] = None
    accuracy_score: float
    fluency_score: float
    completeness_score: float
    pronunciation_score: float
    words: List[Dict[str, Any]]  # ä¿ç•™èˆŠç‰ˆç›¸å®¹æ€§
    detailed_words: Optional[List[Dict[str, Any]]] = None  # æ–°ç‰ˆè©³ç´°è³‡æ–™
    word_details: Optional[List[Dict[str, Any]]] = None  # èˆŠç‰ˆç°¡åŒ–è³‡æ–™
    reference_text: str
    recognized_text: Optional[str] = None
    prosody_score: Optional[float] = None
    analysis_summary: Optional[Dict[str, Any]] = None
    created_at: Optional[datetime] = None


# Commented out - no longer using Cloud Tasks for background analysis
# class AssessAsyncRequest(BaseModel):
#     """éåŒæ­¥ç™¼éŸ³è©•ä¼°è«‹æ±‚ schema (Cloud Tasks)"""
#     progress_id: int
#     audio_url: str
#     reference_text: str


def convert_audio_to_wav(audio_data: bytes, content_type: str) -> bytes:
    """
    å°‡éŸ³æª”è½‰æ›ç‚º WAV æ ¼å¼ï¼ˆ16000Hz, 16bit, monoï¼‰
    Azure Speech SDK éœ€è¦ç‰¹å®šæ ¼å¼çš„ WAV
    """
    logger.debug(f"Converting audio from {content_type} to WAV")

    try:
        # æ ¹æ“š content type é¸æ“‡æ ¼å¼
        if "webm" in content_type:
            # WebM æ ¼å¼ï¼ˆç€è¦½å™¨éŒ„éŸ³ï¼‰
            with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as temp_in:
                temp_in.write(audio_data)
                temp_in_path = temp_in.name

            # ä½¿ç”¨ pydub è½‰æ›ï¼ˆéœ€è¦ ffmpegï¼‰
            audio = AudioSegment.from_file(temp_in_path, format="webm")
        elif "mp3" in content_type or "mpeg" in content_type:
            # MP3 æ ¼å¼
            audio = AudioSegment.from_mp3(BytesIO(audio_data))
        elif "mp4" in content_type:
            # MP4 æ ¼å¼ï¼ˆmacOS Safariï¼‰
            with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_in:
                temp_in.write(audio_data)
                temp_in_path = temp_in.name
            # ä½¿ç”¨ pydub è½‰æ›ï¼ˆéœ€è¦ ffmpegï¼‰
            audio = AudioSegment.from_file(temp_in_path, format="mp4")
        elif "wav" in content_type:
            # å·²ç¶“æ˜¯ WAVï¼Œä½†å¯èƒ½éœ€è¦è½‰æ›æ¡æ¨£ç‡
            audio = AudioSegment.from_wav(BytesIO(audio_data))
        else:
            # å˜—è©¦è‡ªå‹•åµæ¸¬æ ¼å¼
            audio = AudioSegment.from_file(BytesIO(audio_data))

        # è½‰æ›ç‚º Azure Speech SDK éœ€è¦çš„æ ¼å¼
        # 16000Hz æ¡æ¨£ç‡, å–®è²é“, 16bit
        audio = audio.set_frame_rate(16000)
        audio = audio.set_channels(1)
        audio = audio.set_sample_width(2)  # 16bit = 2 bytes

        # è¼¸å‡ºç‚º WAV
        wav_buffer = BytesIO()
        audio.export(wav_buffer, format="wav")
        wav_data = wav_buffer.getvalue()

        logger.debug(
            f"Converted audio: {len(audio_data)} bytes -> {len(wav_data)} bytes WAV"
        )
        logger.debug(f"Audio duration: {len(audio) / 1000.0} seconds")

        # æ¸…ç†æš«å­˜æª”
        if "temp_in_path" in locals():
            os.unlink(temp_in_path)

        return wav_data

    except Exception as e:
        logger.error(f"Audio conversion failed: {e}")
        raise HTTPException(
            status_code=400, detail=f"Audio format conversion failed: {str(e)}"
        )


@trace_function("Azure Speech Assessment")
def assess_pronunciation(audio_data: bytes, reference_text: str) -> Dict[str, Any]:
    """
    å‘¼å« Azure Speech API é€²è¡Œç™¼éŸ³è©•ä¼°

    Args:
        audio_data: éŸ³æª”äºŒé€²ä½è³‡æ–™
        reference_text: åƒè€ƒæ–‡æœ¬

    Returns:
        è©•ä¼°çµæœå­—å…¸ï¼ˆåŒ…å«è©³ç´°çš„éŸ³ç¯€å’ŒéŸ³ç´ è³‡è¨Šï¼‰
    """
    import azure.cognitiveservices.speech as speechsdk
    import time

    # å–å¾— Azure è¨­å®š
    speech_key = os.getenv("AZURE_SPEECH_KEY")
    speech_region = os.getenv("AZURE_SPEECH_REGION", "eastasia")

    logger.debug(f"Azure Speech Key configured: {bool(speech_key)}")
    logger.debug(f"Azure Speech Region: {speech_region}")
    logger.debug(f"Processing audio: {len(audio_data)} bytes")
    logger.debug(f"Reference text: {reference_text}")

    if not speech_key:
        logger.error("AZURE_SPEECH_KEY not configured!")
        raise ValueError("AZURE_SPEECH_KEY not configured")

    # ğŸ• è¨˜éŒ„é–‹å§‹æ™‚é–“ï¼ˆç”¨æ–¼è¨ˆç®— Azure API å»¶é²ï¼‰
    start_time = time.time()

    try:
        # è¨­å®š Speech SDK
        speech_config = speechsdk.SpeechConfig(
            subscription=speech_key, region=speech_region
        )

        # ğŸ”¥ è¨­å®šèªè¨€ç‚ºç¾å¼è‹±èªä»¥æ”¯æ´éŸ»å¾‹è©•ä¼°
        speech_config.speech_recognition_language = "en-US"

        # â±ï¸ è¨­å®šé€£ç·šèˆ‡è­˜åˆ¥è¶…æ™‚ï¼ˆIssue #92 å„ªåŒ–ï¼‰
        # é€£ç·šè¶…æ™‚ï¼š10 ç§’ï¼ˆæ¯”é è¨­çš„ 30 ç§’å¿« 3 å€ï¼‰
        speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs,
            "10000",  # 10 seconds
        )
        # è­˜åˆ¥çµæŸè¶…æ™‚ï¼š2 ç§’ï¼ˆåŠ å¿«è­˜åˆ¥å®Œæˆåˆ¤æ–·ï¼‰
        speech_config.set_property(
            speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs,
            "2000",  # 2 seconds
        )
        logger.info(
            "âœ… Azure Speech SDK timeout configured: connection=10s, end_silence=2s"
        )

        # è¨­å®šç™¼éŸ³è©•ä¼° - å•Ÿç”¨éŸ»å¾‹è©•ä¼°
        pronunciation_config = speechsdk.PronunciationAssessmentConfig(
            reference_text=reference_text,
            grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
            granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,
            enable_miscue=True,
        )

        # å•Ÿç”¨éŸ»å¾‹è©•ä¼°ï¼ˆå¦‚æœ SDK æ”¯æ´ï¼‰
        try:
            pronunciation_config.enable_prosody_assessment = True
            logger.info("âœ… Prosody assessment enabled successfully")
        except Exception as e:
            logger.warning(f"âš ï¸ Prosody assessment not available: {e}")
            logger.info("éŸ»å¾‹è©•ä¼°å¯èƒ½éœ€è¦ç‰¹å®šçš„ SDK ç‰ˆæœ¬æˆ–èªè¨€æ”¯æ´")

        # å¾è¨˜æ†¶é«”å‰µå»ºéŸ³è¨Šæµ
        audio_stream = speechsdk.audio.PushAudioInputStream()
        audio_config = speechsdk.audio.AudioConfig(stream=audio_stream)

        # å‰µå»ºèªéŸ³è­˜åˆ¥å™¨
        speech_recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, audio_config=audio_config
        )

        # å¥—ç”¨ç™¼éŸ³è©•ä¼°é…ç½®
        pronunciation_config.apply_to(speech_recognizer)

        # æ¨é€éŸ³è¨Šè³‡æ–™
        audio_stream.write(audio_data)
        audio_stream.close()

        # ğŸ• è¨˜éŒ„ Azure API å‘¼å«é–‹å§‹æ™‚é–“
        azure_api_start = time.time()

        # åŸ·è¡Œè­˜åˆ¥
        result = speech_recognizer.recognize_once()

        # ğŸ• è¨ˆç®— Azure API å»¶é²
        azure_api_latency = time.time() - azure_api_start
        logger.info(f"â±ï¸ Azure Speech API latency: {azure_api_latency:.2f}s")

        # âš ï¸ å¦‚æœ Azure API å»¶é²è¶…é 5 ç§’ï¼Œè¨˜éŒ„è­¦å‘Š
        if azure_api_latency > 5.0:
            logger.warning(
                f"âš ï¸ Azure Speech API slow response detected! "
                f"Latency: {azure_api_latency:.2f}s (threshold: 5s)"
            )

        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            # å–å¾—è©•ä¼°çµæœ
            pronunciation_result = speechsdk.PronunciationAssessmentResult(result)

            # è¨˜éŒ„åŸå§‹çµæœä»¥ä¾¿èª¿è©¦
            import json

            result_json = json.loads(result.json)
            nbest = result_json.get("NBest", [{}])[0]
            print("\nğŸ” Azure Speech API Raw Result:")
            print(f"Words count: {len(nbest.get('Words', []))}")
            if nbest.get("Words"):
                first_word = nbest["Words"][0]
                print(f"First word: {first_word.get('Word')}")
                print(f"Has Syllables: {'Syllables' in first_word}")
                print(f"Has Phonemes: {'Phonemes' in first_word}")
                if "Syllables" in first_word:
                    print(f"Syllables count: {len(first_word.get('Syllables', []))}")
                if "Phonemes" in first_word:
                    print(f"Phonemes count: {len(first_word.get('Phonemes', []))}")
            print(json.dumps(nbest, indent=2)[:2000])  # åªå°å‰2000å­—å…ƒ

            # è§£æçµæœ - åŒ…å«éŸ»å¾‹åˆ†æ•¸ï¼ˆå¦‚æœæœ‰ï¼‰
            assessment_result = {
                "accuracy_score": pronunciation_result.accuracy_score,
                "fluency_score": pronunciation_result.fluency_score,
                "completeness_score": pronunciation_result.completeness_score,
                "pronunciation_score": pronunciation_result.pronunciation_score,
                "recognized_text": result.text,
                "reference_text": reference_text,
                "words": [],
            }

            # å˜—è©¦å–å¾—éŸ»å¾‹åˆ†æ•¸
            if hasattr(pronunciation_result, "prosody_score"):
                prosody_score = pronunciation_result.prosody_score
                assessment_result["prosody_score"] = prosody_score
                logger.info(f"ğŸµ éŸ»å¾‹åˆ†æ•¸: {prosody_score}")
            else:
                assessment_result["prosody_score"] = None
                logger.info("â„¹ï¸ éŸ»å¾‹åˆ†æ•¸ä¸å¯ç”¨ - å¯èƒ½å› ç‚ºèªè¨€ä¸æ”¯æ´æˆ– SDK ç‰ˆæœ¬é™åˆ¶")

            # ğŸ”¥ ä¿®å¾©ï¼šç›´æ¥è§£æ JSON è³‡æ–™è€Œä¸ä¾è³´ SDK ç‰©ä»¶å±¬æ€§
            # Azure Speech SDK çš„ Python ç‰©ä»¶æ²’æœ‰æ­£ç¢ºæš´éœ² Syllables/Phonemes å±¬æ€§
            # ä½† result.json åŒ…å«å®Œæ•´çš„è³‡æ–™
            words_from_json = nbest.get("Words", [])
            logger.debug(f"Parsing {len(words_from_json)} words from JSON...")

            for idx, word_json in enumerate(words_from_json):
                logger.debug(f"Processing word {idx}: {word_json.get('Word')}")
                try:
                    # å»ºç«‹å–®å­—è³‡æ–™çµæ§‹
                    word_data = {
                        "index": idx,
                        "word": word_json.get("Word", ""),
                        "accuracy_score": word_json.get(
                            "PronunciationAssessment", {}
                        ).get("AccuracyScore", 0),
                        "error_type": word_json.get("PronunciationAssessment", {}).get(
                            "ErrorType", "None"
                        ),
                        "syllables": [],
                        "phonemes": [],
                    }

                    # è§£æéŸ³ç¯€è³‡è¨Šï¼ˆå¾ JSONï¼‰
                    syllables_json = word_json.get("Syllables", [])
                    logger.debug(
                        f"Found {len(syllables_json)} syllables for word '{word_data['word']}'"
                    )

                    for syl_idx, syllable_json in enumerate(syllables_json):
                        syllable_data = {
                            "index": syl_idx,
                            "syllable": syllable_json.get("Syllable", ""),
                            "accuracy_score": syllable_json.get(
                                "PronunciationAssessment", {}
                            ).get("AccuracyScore", 0),
                        }
                        word_data["syllables"].append(syllable_data)
                        logger.debug(f"  Syllable {syl_idx}: {syllable_data}")

                    # è§£æéŸ³ç´ è³‡è¨Šï¼ˆå¾ JSONï¼‰
                    phonemes_json = word_json.get("Phonemes", [])
                    logger.debug(
                        f"Found {len(phonemes_json)} phonemes for word '{word_data['word']}'"
                    )

                    for pho_idx, phoneme_json in enumerate(phonemes_json):
                        phoneme_data = {
                            "index": pho_idx,
                            "phoneme": phoneme_json.get("Phoneme", ""),
                            "accuracy_score": phoneme_json.get(
                                "PronunciationAssessment", {}
                            ).get("AccuracyScore", 0),
                        }
                        word_data["phonemes"].append(phoneme_data)
                        logger.debug(f"  Phoneme {pho_idx}: {phoneme_data}")

                    assessment_result["words"].append(word_data)
                    logger.debug(
                        f"âœ… Processed word: {word_data['word']} (score: {word_data['accuracy_score']}, "
                        f"syllables: {len(word_data['syllables'])}, phonemes: {len(word_data['phonemes'])})"
                    )

                except Exception as e:
                    logger.error(f"Error processing word {idx}: {e}")
                    logger.debug(f"Word JSON details: {word_json}")
                    # ä¸è¦ä¸­æ–·ï¼Œç¹¼çºŒè™•ç†å…¶ä»–å–®å­—
                    word_data = {
                        "index": idx,
                        "word": word_json.get("Word", "") if word_json else "",
                        "accuracy_score": word_json.get(
                            "PronunciationAssessment", {}
                        ).get("AccuracyScore", 0)
                        if word_json
                        else 0,
                        "error_type": "ProcessingError",
                        "syllables": [],
                        "phonemes": [],
                    }
                    assessment_result["words"].append(word_data)

            # ğŸ”¥ ä¿®å¾©ï¼šåœ¨åŸå§‹çµæœä¸­åŠ å…¥ detailed_words ä¾¿æ–¼å‰ç«¯ä½¿ç”¨
            assessment_result["detailed_words"] = assessment_result["words"]

            # ç‚ºç›¸å®¹æ€§åŠ å…¥ word_details
            assessment_result["word_details"] = [
                {
                    "word": w["word"],
                    "accuracy_score": w["accuracy_score"],
                    "error_type": w["error_type"],
                }
                for w in assessment_result["words"]
            ]

            return assessment_result

        elif result.reason == speechsdk.ResultReason.NoMatch:
            raise HTTPException(
                status_code=400, detail="No speech could be recognized from the audio"
            )
        else:
            raise HTTPException(
                status_code=503, detail=f"Speech recognition failed: {result.reason}"
            )

    except Exception as e:
        # ğŸ• è¨ˆç®—ç¸½è™•ç†æ™‚é–“ï¼ˆåŒ…å«å¤±æ•—çš„æƒ…æ³ï¼‰
        total_latency = time.time() - start_time

        logger.error(f"Azure Speech API error: {str(e)}")
        logger.error(f"Total processing time before failure: {total_latency:.2f}s")
        logger.debug(f"Error type: {type(e)}")
        import traceback

        logger.debug(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=503,
            detail={
                "error": "SERVICE_UNAVAILABLE",
                "message": "Azure Speech API unavailable. Please try again later.",
                "latency_seconds": round(total_latency, 2),
            },
        )


def save_assessment_result(
    db: Session,
    progress_id: int,
    assessment_result: Dict[str, Any],
    reference_text: str = "",
    item_index: Optional[int] = None,
    audio_url: Optional[str] = None,
    student_assignment_id: Optional[int] = None,
) -> StudentItemProgress:
    """
    å„²å­˜è©•ä¼°çµæœåˆ° StudentItemProgress
    progress_id æ‡‰è©²æ˜¯ StudentItemProgress çš„ ID
    """
    # æŸ¥æ‰¾ StudentItemProgress è¨˜éŒ„
    progress = (
        db.query(StudentItemProgress)
        .filter(StudentItemProgress.id == progress_id)
        .first()
    )

    if not progress:
        logger.error(
            f"StudentItemProgress with id {progress_id} not found. "
            f"This usually means the recording was not uploaded successfully first."
        )
        raise HTTPException(
            status_code=404,
            detail="Progress record not found - please ensure recording was uploaded first",
        )
    # æ›´æ–° AI è©•ä¼°åˆ†æ•¸ (StudentItemProgress ä½¿ç”¨ç¨ç«‹æ¬„ä½è€Œé JSON)
    progress.accuracy_score = assessment_result["accuracy_score"]
    progress.fluency_score = assessment_result["fluency_score"]
    progress.pronunciation_score = assessment_result["pronunciation_score"]
    progress.completeness_score = assessment_result["completeness_score"]

    # å°‡å®Œæ•´è©•ä¼°çµæœå’Œè©å½™ç´°ç¯€å„²å­˜ç‚º JSON æ ¼å¼çš„ ai_feedback
    # é€™å€‹ JSON åŒ…å«å®Œæ•´çš„ Wordâ†’Syllableâ†’Phoneme å±¤ç´šè³‡è¨Š
    import json

    ai_feedback = {
        # ç¸½é«”åˆ†æ•¸
        "accuracy_score": assessment_result["accuracy_score"],
        "fluency_score": assessment_result["fluency_score"],
        "pronunciation_score": assessment_result["pronunciation_score"],
        "completeness_score": assessment_result["completeness_score"],
        # æ–‡æœ¬è³‡è¨Š
        "reference_text": assessment_result.get("reference_text", reference_text),
        "recognized_text": assessment_result.get("recognized_text", ""),
        # èˆŠç‰ˆç›¸å®¹ï¼ˆç°¡åŒ–çš„å–®å­—è©³æƒ…ï¼‰
        "word_details": [
            {
                "word": w["word"],
                "accuracy_score": w["accuracy_score"],
                "error_type": w["error_type"],
            }
            for w in assessment_result["words"]
        ],
        # æ–°ç‰ˆè©³ç´°è³‡è¨Šï¼ˆåŒ…å«éŸ³ç¯€å’ŒéŸ³ç´ ï¼‰
        "detailed_words": assessment_result["words"],
        # åˆ†ææ‘˜è¦
        "analysis_summary": {
            "total_words": len(assessment_result["words"]),
            "problematic_words": [
                w["word"]
                for w in assessment_result["words"]
                if w["accuracy_score"] < 80
            ],
            "low_score_phonemes": [],  # æ”¶é›†ä½åˆ†éŸ³ç´ 
            "assessment_time": datetime.now().isoformat(),
        },
    }

    # æ”¶é›†ä½åˆ†éŸ³ç´ ç”¨æ–¼æ•™å­¸å»ºè­°
    for word in assessment_result["words"]:
        for phoneme in word.get("phonemes", []):
            if phoneme["accuracy_score"] < 70:
                ai_feedback["analysis_summary"]["low_score_phonemes"].append(
                    {
                        "phoneme": phoneme["phoneme"],
                        "score": phoneme["accuracy_score"],
                        "in_word": word["word"],
                    }
                )

    # å¦‚æœæœ‰éŸ»å¾‹åˆ†æ•¸ï¼ŒåŠ å…¥
    if "prosody_score" in assessment_result:
        ai_feedback["prosody_score"] = assessment_result["prosody_score"]

    progress.ai_feedback = json.dumps(ai_feedback)

    # æ›´æ–°è©•ä¼°æ™‚é–“
    progress.ai_assessed_at = datetime.now()

    # æ›´æ–°ç‹€æ…‹ç‚ºå·²å®Œæˆ
    progress.status = "SUBMITTED"
    progress.submitted_at = datetime.now()

    db.commit()
    db.refresh(progress)

    return progress


@router.post("/assess", response_model=AssessmentResponse)
@trace_function("Speech Assessment API")
async def assess_pronunciation_endpoint(
    audio_file: UploadFile = File(...),
    reference_text: str = Form(...),
    progress_id: int = Form(...),
    item_index: Optional[int] = Form(None),  # é¡Œç›®ç´¢å¼•
    assignment_id: Optional[int] = Form(None),  # ğŸ”¥ é€™æ˜¯ StudentAssignment.id (å­¸ç”Ÿä½œæ¥­ID)
    db: Session = Depends(get_db),
    current_student: Student = Depends(get_current_student),
):
    """
    è©•ä¼°å­¸ç”Ÿç™¼éŸ³

    - **audio_file**: éŸ³æª”ï¼ˆWAV, WebM, MP3ï¼‰
    - **reference_text**: åƒè€ƒæ–‡æœ¬
    - **progress_id**: StudentContentProgress è¨˜éŒ„çš„ ID
    """
    perf = PerformanceSnapshot(f"Speech_Assessment_Student_{current_student.id}")

    # æª¢æŸ¥æª”æ¡ˆæ ¼å¼
    if audio_file.content_type not in ALLOWED_AUDIO_FORMATS:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported audio format. Allowed formats: {', '.join(ALLOWED_AUDIO_FORMATS)}",
        )

    # æª¢æŸ¥æª”æ¡ˆå¤§å°
    with start_span("Read Audio File"):
        audio_data = await audio_file.read()
        if len(audio_data) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"File too large. Maximum size: {MAX_FILE_SIZE / 1024 / 1024}MB",
            )
        perf.checkpoint("Audio File Read")

    # è½‰æ›éŸ³æª”æ ¼å¼ç‚º WAVï¼ˆAzure Speech SDK éœ€è¦ï¼‰
    # âš¡ éŸ³æª”è½‰æ›ä¹Ÿå¯èƒ½è€—æ™‚ï¼Œä½¿ç”¨è‡ªè¨‚ç·šç¨‹æ± é¿å…é˜»å¡
    with start_span("Convert Audio to WAV"):
        import time

        conversion_start = time.time()
        loop = asyncio.get_event_loop()
        audio_pool = get_audio_thread_pool()
        wav_audio_data = await loop.run_in_executor(
            audio_pool, convert_audio_to_wav, audio_data, audio_file.content_type
        )
        conversion_time = time.time() - conversion_start
        logger.info(f"â±ï¸ Audio conversion time: {conversion_time:.2f}s")
        perf.checkpoint("Audio Conversion Complete")

    # ğŸ¯ æ‰¾åˆ°å­¸ç”Ÿçš„ assignment èˆ‡è€å¸«ï¼ˆé…é¡æª¢æŸ¥ï¼‰
    student_assignment_id = None
    teacher = None
    assignment = None

    # ğŸ” Debug: æª¢æŸ¥å‰ç«¯å‚³å…¥çš„ assignment_id (å¯¦éš›ä¸Šæ˜¯ StudentAssignment.id)
    print(
        f"ğŸ” Received assignment_id (StudentAssignment.id) from frontend: {assignment_id}"
    )
    logger.info(f"ğŸ” Received assignment_id (StudentAssignment.id): {assignment_id}")

    if assignment_id:
        print("âœ… assignment_id exists, querying StudentAssignment by ID...")
        # ğŸ”¥ å„ªåŒ–ï¼šä½¿ç”¨ joinedload æ¸›å°‘è³‡æ–™åº«æŸ¥è©¢æ¬¡æ•¸ï¼ˆ3æ¬¡ â†’ 1æ¬¡ï¼‰
        student_assignment = (
            db.query(StudentAssignment)
            .options(
                joinedload(StudentAssignment.assignment).joinedload(Assignment.teacher)
            )
            .filter(
                StudentAssignment.id == assignment_id,
                StudentAssignment.student_id == current_student.id,
            )
            .first()
        )
        if student_assignment:
            student_assignment_id = student_assignment.id
            print(
                "âœ… Found StudentAssignment: "
                f"id={student_assignment.id}, "
                f"assignment_id={student_assignment.assignment_id}"
            )

            # å¾å·²ç¶“ join çš„ç‰©ä»¶ç›´æ¥å–å¾— (ä¸ç”¨å†æŸ¥è©¢)
            assignment = student_assignment.assignment
            if assignment:
                print(
                    f"âœ… Found Assignment: {assignment.id}, teacher_id={assignment.teacher_id}"
                )
                teacher = assignment.teacher
                if teacher:
                    print(f"âœ… Found Teacher: {teacher.id} ({teacher.name})")
                else:
                    print(f"âŒ Teacher not found for assignment {assignment.id}")
            else:
                print(
                    f"âŒ Assignment not found with id {student_assignment.assignment_id}"
                )
        else:
            print(
                f"âŒ StudentAssignment not found for id={assignment_id}, student_id={current_student.id}"
            )

    # ğŸ“Š é…é¡æª¢æŸ¥ï¼ˆåƒ…è¨˜éŒ„ç‹€æ…‹ï¼Œä¸é˜»æ“‹å­¸ç”Ÿå­¸ç¿’ï¼‰
    if teacher and assignment:
        # è¨ˆç®—éŒ„éŸ³æ™‚é•·
        try:
            audio = AudioSegment.from_file(BytesIO(audio_data))
            duration_seconds = len(audio) / 1000.0  # æ¯«ç§’è½‰ç§’

            # âš ï¸ æ¥­å‹™éœ€æ±‚ï¼šé…é¡è¶…é™ä¸æ‡‰é˜»æ“‹å­¸ç”Ÿå­¸ç¿’ï¼Œåªè¨˜éŒ„ä½¿ç”¨é‡
            if not QuotaService.check_quota(teacher, int(duration_seconds)):
                quota_info = QuotaService.get_quota_info(teacher)
                logger.warning(
                    f"âš ï¸ Teacher {teacher.id} quota exceeded, but allowing student to continue learning. "
                    f"Required: {int(duration_seconds)}s, Available: {quota_info['quota_remaining']}s"
                )
            else:
                logger.info(
                    f"âœ… Quota check passed: {duration_seconds:.1f}s for teacher {teacher.id}"
                )
        except Exception as e:
            logger.error(f"âŒ Quota check failed: {e}")
            # è¨ˆç®—æ™‚é•·å¤±æ•—ï¼Œå…è¨±ç¹¼çºŒè©•åˆ†

    # é€²è¡Œç™¼éŸ³è©•ä¼°ï¼ˆAzure Speech SDKï¼‰
    # âš¡ ä½¿ç”¨è‡ªè¨‚èªéŸ³ç·šç¨‹æ± é¿å…é˜»å¡ event loop
    # ğŸ• åŠ å…¥ timeout ä¿è­·é¿å…é•·æ™‚é–“é˜»å¡
    with start_span(
        "Azure Speech API Call", {"reference_text_length": len(reference_text)}
    ):
        loop = asyncio.get_event_loop()
        speech_pool = get_speech_thread_pool()

        try:
            # ğŸ• ä½¿ç”¨ asyncio.wait_for åŠ å…¥ timeoutï¼ˆé è¨­ 20 ç§’ï¼‰
            assessment_result = await asyncio.wait_for(
                loop.run_in_executor(
                    speech_pool, assess_pronunciation, wav_audio_data, reference_text
                ),
                timeout=AZURE_SPEECH_TIMEOUT,
            )
            perf.checkpoint("Azure Speech Assessment Complete")

        except asyncio.TimeoutError:
            # ğŸ• Azure API timeout - è¨˜éŒ„åˆ° BigQuery
            timeout_duration = AZURE_SPEECH_TIMEOUT
            logger.error(
                f"âŒ Azure Speech API timeout after {timeout_duration}s "
                f"for student {current_student.id}"
            )

            # ğŸ“Š è¨˜éŒ„åˆ° BigQuery
            bigquery_logger = get_bigquery_logger()
            await bigquery_logger.log_audio_error(
                {
                    "timestamp": datetime.utcnow().isoformat(),
                    "error_type": "api_timeout",
                    "error_message": f"Azure Speech API timeout after {timeout_duration}s",
                    "student_id": current_student.id,
                    "assignment_id": assignment_id,
                    "audio_size_bytes": len(audio_data),
                    "reference_text": reference_text,
                    "timeout_seconds": timeout_duration,
                    "environment": os.getenv("ENVIRONMENT", "unknown"),
                }
            )

            raise HTTPException(
                status_code=503,
                detail={
                    "error": "API_TIMEOUT",
                    "message": f"èªéŸ³è©•ä¼°æœå‹™è™•ç†è¶…æ™‚ï¼ˆ{timeout_duration} ç§’ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦",
                    "timeout_seconds": timeout_duration,
                },
            )

        except HTTPException as e:
            # ğŸ”¥ æ•æ‰ assess_pronunciation å…§éƒ¨çš„ 503 éŒ¯èª¤ä¸¦è¨˜éŒ„åˆ° BigQuery
            if e.status_code == 503:
                logger.error(
                    f"âŒ Azure Speech API error (503) for student {current_student.id}: {e.detail}"
                )

                # ğŸ“Š è¨˜éŒ„åˆ° BigQuery
                bigquery_logger = get_bigquery_logger()
                error_detail = (
                    e.detail
                    if isinstance(e.detail, dict)
                    else {"message": str(e.detail)}
                )
                await bigquery_logger.log_audio_error(
                    {
                        "timestamp": datetime.utcnow().isoformat(),
                        "error_type": "api_error_503",
                        "error_message": error_detail.get("message", str(e.detail)),
                        "student_id": current_student.id,
                        "assignment_id": assignment_id,
                        "audio_size_bytes": len(audio_data),
                        "reference_text": reference_text,
                        "latency_seconds": error_detail.get("latency_seconds"),
                        "environment": os.getenv("ENVIRONMENT", "unknown"),
                    }
                )

            # é‡æ–°æ‹‹å‡ºåŸå§‹ HTTPException
            raise

    # ğŸ“Š è©•åˆ†æˆåŠŸå¾Œæ‰£é™¤é…é¡
    if teacher and assignment:
        try:
            audio = AudioSegment.from_file(BytesIO(audio_data))
            duration_seconds = len(audio) / 1000.0

            # æ‰£é™¤è€å¸«çš„é…é¡ä¸¦è¨˜éŒ„
            QuotaService.deduct_quota(
                db=db,
                teacher=teacher,
                student_id=current_student.id,
                assignment_id=assignment.id,
                feature_type="speech_assessment",
                unit_count=duration_seconds,
                unit_type="ç§’",
                feature_detail={
                    "reference_text": reference_text,
                    "accuracy_score": assessment_result["accuracy_score"],
                    "audio_size_bytes": len(audio_data),
                },
            )
            logger.info(
                f"âœ… Deducted {duration_seconds:.1f}s quota from teacher {teacher.id} "
                f"for student {current_student.id} assignment {assignment.id}"
            )
        except HTTPException as e:
            # é…é¡æ‰£é™¤å¤±æ•—ï¼ˆå¯èƒ½æ˜¯ç¡¬é™åˆ¶è¶…é¡ï¼‰ï¼Œå‘å­¸ç”Ÿé¡¯ç¤ºå‹å–„è¨Šæ¯
            if e.status_code == 402 and isinstance(e.detail, dict):
                error_type = e.detail.get("error")
                if error_type == "QUOTA_HARD_LIMIT_EXCEEDED":
                    # ç¡¬é™åˆ¶è¶…é¡ï¼Œå­¸ç”Ÿçœ‹åˆ°å‹å–„è¨Šæ¯
                    logger.error(
                        f"âŒ Quota hard limit exceeded for teacher {teacher.id}, "
                        f"blocking student {current_student.id}"
                    )
                    raise HTTPException(
                        status_code=402,
                        detail={
                            "error": "QUOTA_HARD_LIMIT_EXCEEDED",
                            "message": "è€å¸«çš„é…é¡å·²ç”¨å®Œï¼ˆå«ç·©è¡é¡åº¦ï¼‰ï¼Œè«‹è¯ç¹«è€å¸«çºŒè²»å¾Œå†ç¹¼çºŒä½¿ç”¨",
                            "teacher_quota_info": e.detail,
                        },
                    )
            # å…¶ä»– HTTPException ç›´æ¥æ‹‹å‡º
            raise
        except Exception as e:
            logger.error(f"âŒ Quota deduction failed: {e}")
            # å…¶ä»–éŒ¯èª¤åªè¨˜éŒ„ï¼Œä¸å½±éŸ¿è©•åˆ†çµæœ

    # å„²å­˜çµæœåˆ°è³‡æ–™åº«
    with start_span("Save Assessment Result to Database"):
        updated_progress = save_assessment_result(
            db=db,
            progress_id=progress_id,
            assessment_result=assessment_result,
            reference_text=reference_text,
            item_index=item_index,
            student_assignment_id=student_assignment_id,
        )
        perf.checkpoint("Database Save Complete")

    # å®Œæˆæ•ˆèƒ½è¿½è¹¤
    perf.finish()

    # å›å‚³çµæœ - åŒ…å«å®Œæ•´çš„è©³ç´°è³‡æ–™
    return AssessmentResponse(
        id=updated_progress.id,
        accuracy_score=assessment_result["accuracy_score"],
        fluency_score=assessment_result["fluency_score"],
        completeness_score=assessment_result["completeness_score"],
        pronunciation_score=assessment_result["pronunciation_score"],
        words=assessment_result["words"],  # ä¿ç•™èˆŠç‰ˆç›¸å®¹æ€§
        detailed_words=assessment_result.get("detailed_words"),  # ğŸ”¥ æ–°ç‰ˆè©³ç´°è³‡æ–™
        word_details=assessment_result.get("word_details"),  # èˆŠç‰ˆç°¡åŒ–è³‡æ–™
        reference_text=reference_text,
        recognized_text=assessment_result.get("recognized_text"),
        prosody_score=assessment_result.get("prosody_score"),
        analysis_summary=assessment_result.get("analysis_summary"),
        created_at=updated_progress.submitted_at,
    )


@router.get("/assessments", response_model=List[AssessmentResponse])
async def get_student_assessments(
    skip: int = 0,
    limit: int = 20,
    db: Session = Depends(get_db),
    current_student: Student = Depends(get_current_student),
):
    """
    ç²å–å­¸ç”Ÿçš„è©•ä¼°æ­·å²è¨˜éŒ„
    """
    # æŸ¥è©¢æœ‰ ai_scores çš„ StudentContentProgress è¨˜éŒ„ï¼Œåªé¡¯ç¤ºç•¶å‰å­¸ç”Ÿçš„è¨˜éŒ„
    # ğŸ”¥ å„ªåŒ–ï¼šä½¿ç”¨ joinedload é è¼‰ contentï¼Œé¿å… N+1 æŸ¥è©¢
    progress_records = (
        db.query(StudentContentProgress)
        .join(StudentContentProgress.student_assignment)
        .options(joinedload(StudentContentProgress.content))
        .filter(
            StudentContentProgress.ai_scores.isnot(None),
            StudentAssignment.student_id == current_student.id,
        )
        .order_by(StudentContentProgress.completed_at.desc())
        .offset(skip)
        .limit(limit)
        .all()
    )

    results = []
    for progress in progress_records:
        ai_scores = progress.ai_scores or {}
        results.append(
            AssessmentResponse(
                id=progress.id,
                accuracy_score=ai_scores.get("accuracy_score", 0.0),
                fluency_score=ai_scores.get("fluency_score", 0.0),
                completeness_score=ai_scores.get("completeness_score", 0.0),
                pronunciation_score=ai_scores.get("pronunciation_score", 0.0),
                words=ai_scores.get("word_details", []),
                reference_text=progress.content.text if progress.content else "",
                created_at=progress.completed_at,
            )
        )

    return results


@router.get("/assessments/{progress_id}", response_model=AssessmentResponse)
async def get_assessment_by_id(
    progress_id: int,
    db: Session = Depends(get_db),
    current_student: Student = Depends(get_current_student),
):
    """
    ç²å–ç‰¹å®šè©•ä¼°çš„è©³ç´°è³‡æ–™
    """
    progress = (
        db.query(StudentContentProgress)
        .filter(
            StudentContentProgress.id == progress_id,
            StudentContentProgress.ai_scores.isnot(None),
        )
        .first()
    )

    if not progress:
        raise HTTPException(status_code=404, detail="Assessment not found")

    ai_scores = progress.ai_scores or {}

    return AssessmentResponse(
        id=progress.id,
        accuracy_score=ai_scores.get("accuracy_score", 0.0),
        fluency_score=ai_scores.get("fluency_score", 0.0),
        completeness_score=ai_scores.get("completeness_score", 0.0),
        pronunciation_score=ai_scores.get("pronunciation_score", 0.0),
        words=ai_scores.get("word_details", []),
        reference_text=progress.content.text if progress.content else "",
        created_at=progress.completed_at,
    )


@router.delete("/assessment/{assignment_id}/item/{item_index}")
async def delete_item_recording_and_assessment(
    assignment_id: int,
    item_index: int,
    db: Session = Depends(get_db),
    current_student: Student = Depends(get_current_student),
):
    """
    åˆªé™¤å­¸ç”Ÿä½œæ¥­çš„æŸå€‹ item çš„éŒ„éŸ³å’Œè©•ä¼°çµæœ

    æ¸…ç©º StudentItemProgress ä¸­çš„ï¼š
    - éŒ„éŸ³ URL (recording_url)
    - è©•ä¼°åˆ†æ•¸ (accuracy_score, fluency_score, pronunciation_score)
    - AI åé¥‹ (ai_feedback, transcription)
    - è©•ä¼°æ™‚é–“ (ai_assessed_at)

    Args:
        assignment_id: StudentAssignment ID
        item_index: Content item çš„ç´¢å¼•

    Returns:
        æˆåŠŸè¨Šæ¯
    """
    logger.info(
        f"Student {current_student.id} deleting recording for assignment {assignment_id}, item {item_index}"
    )

    # 1. æŸ¥æ‰¾ StudentAssignmentï¼ˆç¢ºèªæ¬Šé™ï¼‰
    student_assignment = (
        db.query(StudentAssignment)
        .filter(
            StudentAssignment.id == assignment_id,
            StudentAssignment.student_id == current_student.id,
        )
        .first()
    )

    if not student_assignment:
        logger.warning(
            f"Assignment {assignment_id} not found or not owned by student {current_student.id}"
        )
        raise HTTPException(
            status_code=404,
            detail="Assignment not found or you don't have permission to delete this recording",
        )

    # 2. ç²å–ä½œæ¥­çš„æ‰€æœ‰ content_itemsï¼ˆæŒ‰ order_index æ’åºï¼‰
    # é¦–å…ˆç²å–ä½œæ¥­çš„ content_ids
    progress_records = (
        db.query(StudentContentProgress)
        .filter(StudentContentProgress.student_assignment_id == student_assignment.id)
        .order_by(StudentContentProgress.order_index)
        .all()
    )

    if not progress_records:
        logger.warning(
            f"No content progress records found for assignment {assignment_id}"
        )
        return {"message": "No recording or assessment to delete", "deleted": False}

    # ç²å–æ‰€æœ‰ content_items
    content_ids = [p.content_id for p in progress_records]
    all_content_items = []
    for content_id in content_ids:
        items = (
            db.query(ContentItem)
            .filter(ContentItem.content_id == content_id)
            .order_by(ContentItem.order_index)
            .all()
        )
        all_content_items.extend(items)

    # æª¢æŸ¥ item_index æ˜¯å¦æœ‰æ•ˆ
    if item_index < 0 or item_index >= len(all_content_items):
        logger.warning(
            f"Invalid item_index {item_index} for assignment {assignment_id} (total items: {len(all_content_items)})"
        )
        raise HTTPException(
            status_code=400,
            detail=f"Invalid item index {item_index}",
        )

    # ç²å–å°æ‡‰çš„ ContentItem
    target_item = all_content_items[item_index]

    # 3. æŸ¥æ‰¾ StudentItemProgress
    progress = (
        db.query(StudentItemProgress)
        .filter(
            StudentItemProgress.student_assignment_id == student_assignment.id,
            StudentItemProgress.content_item_id == target_item.id,
        )
        .first()
    )

    if not progress:
        # å¦‚æœæ²’æœ‰è¨˜éŒ„ï¼Œç›´æ¥è¿”å›æˆåŠŸï¼ˆå†ªç­‰æ€§ï¼‰
        logger.info(
            f"No progress record for assignment {assignment_id}, "
            f"item {item_index} (content_item_id: {target_item.id})"
        )
        return {
            "message": "No recording or assessment to delete",
            "deleted": False,
        }

    # 4. æ¸…ç©ºæ‰€æœ‰éŒ„éŸ³å’Œè©•ä¼°ç›¸é—œæ¬„ä½
    progress.recording_url = None
    progress.answer_text = None
    progress.transcription = None
    progress.accuracy_score = None
    progress.fluency_score = None
    progress.pronunciation_score = None
    progress.completeness_score = None
    progress.ai_feedback = None
    progress.ai_assessed_at = None
    progress.submitted_at = None

    # 5. é‡ç½®ç‹€æ…‹ç‚ºæœªé–‹å§‹
    progress.status = "NOT_STARTED"

    db.commit()

    logger.info(
        f"Successfully cleared recording and assessment for assignment {assignment_id}, item {item_index}"
    )

    return {
        "message": "Recording and assessment deleted successfully",
        "deleted": True,
        "progress_id": progress.id,
    }


# ===== æ¸¬è©¦ Endpointï¼šé©—è­‰ Thread Pool ä¸¦ç™¼ =====


@router.get("/test-concurrent")
async def test_thread_pool_concurrent():
    """
    æ¸¬è©¦ Thread Pool ä¸¦ç™¼è™•ç†èƒ½åŠ›
    æ¨¡æ“¬ Azure Speech API çš„é˜»å¡æ“ä½œï¼ˆ1 ç§’ï¼‰
    """
    import time

    loop = asyncio.get_event_loop()
    pool = get_speech_thread_pool()

    def simulate_azure_call():
        """æ¨¡æ“¬ Azure Speech API å‘¼å«ï¼ˆé˜»å¡ 1 ç§’ï¼‰"""
        time.sleep(1)
        return {"simulation": True, "duration": 1.0, "worker": "speech_pool"}

    start = time.time()
    result = await loop.run_in_executor(pool, simulate_azure_call)
    elapsed = time.time() - start

    return {
        "result": result,
        "elapsed_seconds": round(elapsed, 2),
        "thread_pool": {"max_workers": 20, "type": "speech_pool"},
    }


# Commented out - no longer using Cloud Tasks for background analysis
# This endpoint can be re-enabled later for teacher-triggered batch analysis
# @router.post("/assess-async")
# async def assess_async(
#     request: AssessAsyncRequest,
#     db: Session = Depends(get_db)
# ):
#     """
#     éåŒæ­¥ç™¼éŸ³è©•ä¼°ç«¯é» (Cloud Task å‘¼å«)
#
#     æ­¤ç«¯é»ç”± Cloud Tasks å‘¼å«ï¼Œä¸éœ€è¦èªè­‰ tokenï¼Œå› ç‚ºæ˜¯å…§éƒ¨æœå‹™å‘¼å«ã€‚
#     å¦‚æœéœ€è¦åŠ å¼·å®‰å…¨æ€§ï¼Œå¯ä»¥æª¢æŸ¥è«‹æ±‚ä¾†æº IP æˆ–ä½¿ç”¨æœå‹™å¸³è™Ÿèªè­‰ã€‚
#     """
#     pass
