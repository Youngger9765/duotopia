# Load Testing Quick Reference Card

## ğŸš€ Quick Start (3 Steps)

```bash
# 1. Install
pip install -r requirements.txt && python generate_audio_samples.py

# 2. Configure
cp .env.example .env && nano .env  # Add your credentials

# 3. Run
./run_tests.sh --env staging --scenario normal --headless
```

---

## ğŸ“‹ Common Commands

### Basic Test Execution

```bash
# Web UI (interactive)
./run_tests.sh --env staging --scenario normal --web

# Headless (automated)
./run_tests.sh --env staging --scenario peak --headless

# Custom test
./run_tests.sh --env staging --users 30 --rate 5 --time 8m --headless
```

### All Test Scenarios

```bash
# 20 users, 5 minutes
./run_tests.sh --env staging --scenario normal --headless

# 50 users, 5 minutes
./run_tests.sh --env staging --scenario peak --headless

# 100 users, 10 minutes
./run_tests.sh --env staging --scenario stress --headless

# 50 users instantly, 3 minutes
./run_tests.sh --env staging --scenario spike --headless

# 30 users, 30 minutes
./run_tests.sh --env staging --scenario endurance --headless

# 200 users, 10 minutes (find limits)
./run_tests.sh --env staging --scenario breaking --headless
```

---

## ğŸ”§ Environment Variables

```bash
# Set environment
export TEST_ENV=staging  # or production, local

# Override URLs
export STAGING_BASE_URL=https://your-backend-url.run.app

# Set credentials
export TEST_STUDENT_EMAIL=test@example.com
export TEST_STUDENT_PASSWORD=password123

# Set test data IDs
export TEST_ASSIGNMENT_ID=123
export TEST_CONTENT_ITEM_ID=456

# Monitoring
export ENABLE_DB_MONITORING=true
export DB_QUERY_INTERVAL=5
```

---

## ğŸ“Š Interpreting Results

### Good Performance

- âœ… Success rate >95%
- âœ… p95 latency <10s
- âœ… Error rate <2%
- âœ… No 503 errors
- âœ… Stable DB connections

### Warning Signs

- âš ï¸ Success rate 90-95%
- âš ï¸ p95 latency 10-15s
- âš ï¸ Error rate 2-5%
- âš ï¸ Occasional timeouts
- âš ï¸ DB connections >15

### Critical Issues

- âŒ Success rate <90%
- âŒ p95 latency >15s
- âŒ Error rate >5%
- âŒ Frequent 503 errors
- âŒ DB connections >18

---

## ğŸ› Quick Troubleshooting

### Authentication Fails
```bash
# Test login manually
curl -X POST $STAGING_BASE_URL/api/students/validate \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"password"}'
```

### No Assignment Found
```bash
# Set explicit IDs
export TEST_ASSIGNMENT_ID=123
export TEST_CONTENT_ITEM_ID=456
```

### Locust Not Found
```bash
# Reinstall
pip install --upgrade -r requirements.txt
locust --version  # Verify
```

### Database Errors
```bash
# Disable monitoring
export ENABLE_DB_MONITORING=false
```

---

## ğŸ“ File Locations

```
load_testing/
â”œâ”€â”€ run_tests.sh           # Main execution script
â”œâ”€â”€ locustfile.py          # Test scenarios
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ .env                   # Your credentials
â”œâ”€â”€ audio_samples/         # Test files
â””â”€â”€ results/               # Test outputs
    â””â”€â”€ */report.html      # Open in browser
```

---

## ğŸ¯ Test Scenarios Summary

| Scenario | Users | Duration | Purpose |
|----------|-------|----------|---------|
| normal | 20 | 5m | Baseline |
| peak | 50 | 5m | High traffic |
| stress | 100 | 10m | Beyond capacity |
| spike | 50 | 3m | Sudden burst |
| endurance | 30 | 30m | Stability |
| breaking | 200 | 10m | Find limits |

---

## ğŸ“– Documentation

- **Setup**: `SETUP_GUIDE.md`
- **Full Guide**: `README.md`
- **Analysis**: `/docs/LOAD_TESTING_ANALYSIS.md`
- **Summary**: `/docs/LOAD_TESTING_IMPLEMENTATION_SUMMARY.md`

---

## âš ï¸ Production Testing

**Before testing production**:
1. Schedule during low-traffic hours
2. Notify team
3. Start with 10 users
4. Monitor real users
5. Stop if error rate >10%

```bash
# Production test (CAREFUL!)
./run_tests.sh --env production --users 10 --rate 2 --time 3m --headless
```

---

## ğŸ“ Help

1. Check `README.md` Troubleshooting section
2. Review `SETUP_GUIDE.md`
3. Check logs: `locust.log`
4. Contact DevOps team
