"""Audio Error Query Service - BigQuery Integration"""
import os
from datetime import datetime, timedelta
from google.cloud import bigquery
from typing import Dict, Any, List, Optional
import logging
from sqlalchemy import create_engine, select
from sqlalchemy.orm import Session
from models import Student, Classroom, Teacher, ClassroomStudent

logger = logging.getLogger(__name__)


class AudioErrorQueryService:
    """æŸ¥è©¢ BigQuery ä¸­çš„éŒ„éŸ³éŒ¯èª¤æ—¥èªŒ"""

    def __init__(self):
        self.client = None
        self._initialized = False

        # å¾ç’°å¢ƒè®Šæ•¸è®€å–å°ˆæ¡ˆ ID
        self.project_id = os.getenv("GCP_PROJECT_ID", "duotopia-472708")
        self.table_id = f"{self.project_id}.duotopia_logs.audio_playback_errors"

    def _ensure_client(self):
        """å»¶é²åˆå§‹åŒ– BigQuery client"""
        if self._initialized and self.client is not None:
            return

        try:
            # å„ªå…ˆä½¿ç”¨ Application Default Credentials
            self.client = bigquery.Client(project=self.project_id)
            logger.info(
                f"âœ… BigQuery audio error client initialized (project: {self.project_id})"
            )
            logger.info(f"ğŸ“Š BigQuery table: {self.table_id}")
            self._initialized = True
        except Exception as e:
            logger.error(f"âš ï¸ BigQuery client initialization failed: {e}")
            self._initialized = False  # å…è¨±é‡è©¦
            self.client = None

    async def get_error_stats(
        self, days: int = 7, teacher_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        å–å¾—éŒ„éŸ³éŒ¯èª¤çµ±è¨ˆè³‡æ–™

        Args:
            days: æŸ¥è©¢å¤©æ•¸
            teacher_id: è€å¸« IDï¼ˆé¸å¡«ï¼Œç”¨æ–¼éæ¿¾ç‰¹å®šè€å¸«çš„è³‡æ–™ï¼‰

        Returns:
            {
                "total_errors": 123,
                "period": {"start": "2025-01-01", "end": "2025-01-07"},
                "error_by_type": [
                    {"error_type": "DECODE_ERROR", "count": 50},
                    {"error_type": "NETWORK_ERROR", "count": 30}
                ],
                "error_by_date": [
                    {"date": "2025-01-01", "count": 10},
                    ...
                ],
                "error_by_browser": [
                    {"browser": "Chrome", "count": 80},
                    {"browser": "Safari", "count": 40}
                ],
                "data_available": true
            }
        """
        self._ensure_client()

        if self.client is None:
            return {"error": "BigQuery client not available", "data_available": False}

        try:
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            if not await self._check_table_exists():
                logger.info("ğŸ“Š Audio error logs table not yet available")
                return {
                    "total_errors": 0,
                    "period": {
                        "start": (datetime.now() - timedelta(days=days)).strftime(
                            "%Y-%m-%d"
                        ),
                        "end": datetime.now().strftime("%Y-%m-%d"),
                    },
                    "error_by_type": [],
                    "error_by_date": [],
                    "error_by_browser": [],
                    "data_available": False,
                    "message": "ç­‰å¾…éŒ¯èª¤æ—¥èªŒè³‡æ–™",
                }

            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)

            # æŸ¥è©¢åƒæ•¸è¨­å®š
            params = [
                bigquery.ScalarQueryParameter("start_date", "TIMESTAMP", start_date),
                bigquery.ScalarQueryParameter("end_date", "TIMESTAMP", end_date),
            ]

            if teacher_id:
                # Note: ç›®å‰ BigQuery table æ²’æœ‰ teacher_idï¼Œæš«æ™‚è·³é
                # æœªä¾†å¯ä»¥é€é JOIN student_assignments å–å¾—
                pass

            # æŸ¥è©¢çµ±è¨ˆè³‡æ–™ - timestamp æ¬„ä½åœ¨ BigQuery ä¸­æ˜¯ STRINGï¼Œéœ€è¦è½‰æ›
            query = f"""
            SELECT
                COUNT(*) as total_errors,
                error_type,
                DATE(CAST(timestamp AS TIMESTAMP)) as error_date,
                browser,
                platform
            FROM `{self.table_id}`
            WHERE CAST(timestamp AS TIMESTAMP) BETWEEN @start_date AND @end_date
            GROUP BY error_type, error_date, browser, platform
            """

            job_config = bigquery.QueryJobConfig(query_parameters=params)
            query_job = self.client.query(query, job_config=job_config)
            results = list(query_job.result())

            # è¨ˆç®—ç¸½éŒ¯èª¤æ•¸
            total_errors = sum(row.total_errors for row in results)

            # æŒ‰éŒ¯èª¤é¡å‹çµ±è¨ˆ
            error_by_type_dict = {}
            for row in results:
                error_type = row.error_type or "UNKNOWN"
                error_by_type_dict[error_type] = (
                    error_by_type_dict.get(error_type, 0) + row.total_errors
                )

            error_by_type = [
                {"error_type": error_type, "count": count}
                for error_type, count in sorted(
                    error_by_type_dict.items(), key=lambda x: x[1], reverse=True
                )
            ]

            # æŒ‰æ—¥æœŸçµ±è¨ˆ
            error_by_date_dict = {}
            for row in results:
                date_str = row.error_date.strftime("%Y-%m-%d")
                error_by_date_dict[date_str] = (
                    error_by_date_dict.get(date_str, 0) + row.total_errors
                )

            error_by_date = [
                {"date": date, "count": count}
                for date, count in sorted(error_by_date_dict.items())
            ]

            # æŒ‰ç€è¦½å™¨çµ±è¨ˆ
            error_by_browser_dict = {}
            for row in results:
                browser = row.browser or "Unknown"
                error_by_browser_dict[browser] = (
                    error_by_browser_dict.get(browser, 0) + row.total_errors
                )

            error_by_browser = [
                {"browser": browser, "count": count}
                for browser, count in sorted(
                    error_by_browser_dict.items(), key=lambda x: x[1], reverse=True
                )[:10]
            ]

            return {
                "total_errors": total_errors,
                "period": {
                    "start": start_date.strftime("%Y-%m-%d"),
                    "end": end_date.strftime("%Y-%m-%d"),
                },
                "error_by_type": error_by_type,
                "error_by_date": error_by_date,
                "error_by_browser": error_by_browser,
                "data_available": True,
            }

        except Exception as e:
            logger.error(f"âŒ Audio error stats query failed: {e}")
            return {
                "error": str(e),
                "data_available": False,
                "message": "æŸ¥è©¢å¤±æ•—ï¼Œè«‹æª¢æŸ¥ BigQuery æ¬Šé™",
            }

    async def get_error_list(
        self,
        days: int = 7,
        limit: int = 100,
        offset: int = 0,
        search: Optional[str] = None,
        error_type: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        å–å¾—éŒ„éŸ³éŒ¯èª¤è©³ç´°åˆ—è¡¨

        Args:
            days: æŸ¥è©¢å¤©æ•¸
            limit: æ¯é ç­†æ•¸
            offset: åç§»é‡
            search: æœå°‹é—œéµå­—ï¼ˆæœå°‹ error_message, audio_urlï¼‰
            error_type: éŒ¯èª¤é¡å‹éæ¿¾

        Returns:
            {
                "total": 500,
                "data": [
                    {
                        "timestamp": "2025-01-01T10:30:00",
                        "error_type": "DECODE_ERROR",
                        "error_message": "...",
                        "student_id": 123,
                        "assignment_id": 456,
                        "audio_url": "...",
                        "browser": "Chrome",
                        "platform": "macOS",
                        ...
                    }
                ],
                "has_more": true
            }
        """
        self._ensure_client()

        if self.client is None:
            return {"error": "BigQuery client not available", "data": []}

        try:
            if not await self._check_table_exists():
                return {"total": 0, "data": [], "has_more": False}

            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)

            # å»ºç«‹æŸ¥è©¢æ¢ä»¶
            where_clauses = [
                "CAST(timestamp AS TIMESTAMP) BETWEEN @start_date AND @end_date"
            ]
            params = [
                bigquery.ScalarQueryParameter("start_date", "TIMESTAMP", start_date),
                bigquery.ScalarQueryParameter("end_date", "TIMESTAMP", end_date),
            ]

            if error_type:
                where_clauses.append("error_type = @error_type")
                params.append(
                    bigquery.ScalarQueryParameter("error_type", "STRING", error_type)
                )

            if search:
                where_clauses.append(
                    "(LOWER(error_message) LIKE @search OR LOWER(audio_url) LIKE @search)"
                )
                params.append(
                    bigquery.ScalarQueryParameter(
                        "search", "STRING", f"%{search.lower()}%"
                    )
                )

            where_clause = " AND ".join(where_clauses)

            # æŸ¥è©¢ç¸½ç­†æ•¸
            count_query = f"""
            SELECT COUNT(*) as total
            FROM `{self.table_id}`
            WHERE {where_clause}
            """

            job_config = bigquery.QueryJobConfig(query_parameters=params)
            count_job = self.client.query(count_query, job_config=job_config)
            total = list(count_job.result())[0].total

            # æŸ¥è©¢è³‡æ–™åˆ—è¡¨ - éœ€è¦ JOIN PostgreSQL çš„å­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡æ–™
            # æ³¨æ„ï¼šBigQuery ç„¡æ³•ç›´æ¥ JOIN PostgreSQLï¼Œæ‰€ä»¥æˆ‘å€‘å…ˆæŸ¥è©¢ BigQuery è³‡æ–™ï¼Œ
            # ç„¶å¾Œåœ¨ Python ä¸­è£œå……å­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡è¨Š
            data_query = f"""
            SELECT
                timestamp,
                error_type,
                error_code,
                error_message,
                audio_url,
                audio_size,
                audio_duration,
                content_type,
                user_agent,
                platform,
                browser,
                browser_version,
                device_model,
                is_mobile,
                screen_resolution,
                connection_type,
                student_id,
                assignment_id,
                page_url,
                can_play_webm,
                can_play_mp4,
                load_time_ms
            FROM `{self.table_id}`
            WHERE {where_clause}
            ORDER BY timestamp DESC
            LIMIT @limit
            OFFSET @offset
            """

            params.extend(
                [
                    bigquery.ScalarQueryParameter("limit", "INT64", limit),
                    bigquery.ScalarQueryParameter("offset", "INT64", offset),
                ]
            )

            job_config = bigquery.QueryJobConfig(query_parameters=params)
            data_job = self.client.query(data_query, job_config=job_config)
            rows = list(data_job.result())

            # æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è©¢çš„ student_id
            student_ids = [row.student_id for row in rows if row.student_id]

            # å¾ PostgreSQL æŸ¥è©¢å­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡è¨Š
            student_info_map = {}
            if student_ids:
                student_info_map = await self._fetch_student_info(student_ids)

            # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨ï¼Œä¸¦è£œå……å­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡è¨Š
            data = []
            for row in rows:
                student_info = student_info_map.get(row.student_id, {})
                data.append(
                    {
                        "timestamp": row.timestamp,
                        "error_type": row.error_type,
                        "error_code": row.error_code,
                        "error_message": row.error_message,
                        "audio_url": row.audio_url,
                        "audio_size": row.audio_size,
                        "audio_duration": row.audio_duration,
                        "content_type": row.content_type,
                        "user_agent": row.user_agent,
                        "platform": row.platform,
                        "browser": row.browser,
                        "browser_version": row.browser_version,
                        "device_model": row.device_model,
                        "is_mobile": row.is_mobile,
                        "screen_resolution": row.screen_resolution,
                        "connection_type": row.connection_type,
                        "student_id": row.student_id,
                        "assignment_id": row.assignment_id,
                        "page_url": row.page_url,
                        "can_play_webm": row.can_play_webm,
                        "can_play_mp4": row.can_play_mp4,
                        "load_time_ms": row.load_time_ms,
                        # æ–°å¢ï¼šå­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡è¨Šï¼ˆå« IDï¼‰
                        "student_name": student_info.get("student_name"),
                        "classroom_id": student_info.get("classroom_id"),
                        "classroom_name": student_info.get("classroom_name"),
                        "teacher_id": student_info.get("teacher_id"),
                        "teacher_name": student_info.get("teacher_name"),
                    }
                )

            return {"total": total, "data": data, "has_more": (offset + limit) < total}

        except Exception as e:
            logger.error(f"âŒ Audio error list query failed: {e}")
            return {"error": str(e), "data": []}

    async def _check_table_exists(self) -> bool:
        """æª¢æŸ¥ BigQuery è¡¨æ ¼æ˜¯å¦å­˜åœ¨"""
        try:
            self.client.get_table(self.table_id)
            return True
        except Exception as e:
            logger.error(f"âš ï¸ Failed to check table: {e}")
            return False

    async def _fetch_student_info(self, student_ids: List[int]) -> dict:
        """
        å¾ç”Ÿç”¢ç’°å¢ƒ Supabase æŸ¥è©¢å­¸ç”Ÿã€ç­ç´šã€è€å¸«è³‡è¨Š

        âš ï¸ æ³¨æ„ï¼šæ­¤æ–¹æ³•æ°¸é é€£æ¥åˆ°ç”Ÿç”¢ç’°å¢ƒè³‡æ–™åº«ï¼Œä¸å—ç•¶å‰ç’°å¢ƒå½±éŸ¿
        åŸå› ï¼šBigQuery éŒ¯èª¤æ—¥èªŒæ˜¯å…¨å±€çš„ï¼Œéœ€è¦æŸ¥è©¢ç”Ÿç”¢ç’°å¢ƒçš„å­¸ç”Ÿè³‡æ–™

        Returns:
            {
                student_id: {
                    "student_id": 123,
                    "student_name": "å¼µä¸‰",
                    "classroom_id": 456,
                    "classroom_name": "ä¸‰å¹´ä¸€ç­",
                    "teacher_id": 789,
                    "teacher_name": "æè€å¸«"
                }
            }
        """
        try:
            # ğŸ”¥ å¾ç’°å¢ƒè®Šæ•¸è®€å–ç”Ÿç”¢ç’°å¢ƒè³‡æ–™åº« URL
            # åœ¨æ‰€æœ‰ç’°å¢ƒ (.env.local, .env.staging, .env.production) éƒ½éœ€è¦è¨­å®šæ­¤è®Šæ•¸
            prod_db_url = os.getenv("PROD_DATABASE_POOLER_URL")

            if not prod_db_url:
                logger.error("âŒ PROD_DATABASE_POOLER_URL not set in environment")
                return {}

            # å‰µå»ºç”Ÿç”¢ç’°å¢ƒå°ˆç”¨é€£æ¥
            prod_engine = create_engine(
                prod_db_url,
                pool_size=2,
                max_overflow=0,
                pool_pre_ping=True,
            )

            with Session(prod_engine) as db:
                # æŸ¥è©¢å­¸ç”ŸåŠå…¶é—œè¯çš„ç­ç´šã€è€å¸«ï¼ˆé€é ClassroomStudent é—œè¯è¡¨ï¼‰
                stmt = (
                    select(
                        Student.id.label("student_id"),
                        Student.name.label("student_name"),
                        Classroom.id.label("classroom_id"),
                        Classroom.name.label("classroom_name"),
                        Teacher.id.label("teacher_id"),
                        Teacher.name.label("teacher_name"),
                    )
                    .join(
                        ClassroomStudent,
                        Student.id == ClassroomStudent.student_id,
                        isouter=True,
                    )
                    .join(
                        Classroom,
                        ClassroomStudent.classroom_id == Classroom.id,
                        isouter=True,
                    )
                    .join(Teacher, Classroom.teacher_id == Teacher.id, isouter=True)
                    .where(Student.id.in_(student_ids))
                )

                result = db.execute(stmt)
                rows = result.fetchall()

                # å»ºç«‹ student_id -> info çš„ mapping
                student_info_map = {}
                for row in rows:
                    student_info_map[row.student_id] = {
                        "student_id": row.student_id,
                        "student_name": row.student_name,
                        "classroom_id": row.classroom_id,
                        "classroom_name": row.classroom_name,
                        "teacher_id": row.teacher_id,
                        "teacher_name": row.teacher_name,
                    }

                return student_info_map

        except Exception as e:
            logger.error(f"âŒ Failed to fetch student info from production DB: {e}")
            return {}


# å–®ä¾‹æ¨¡å¼
_audio_error_service = None


def get_audio_error_service() -> AudioErrorQueryService:
    """å–å¾— AudioErrorQueryService å–®ä¾‹"""
    global _audio_error_service
    if _audio_error_service is None:
        _audio_error_service = AudioErrorQueryService()
    return _audio_error_service
